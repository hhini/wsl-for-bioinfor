### ğŸ§¬ Dataset Overview

-   **Platform**: Illumina NextSeq 550

-   **Run**: ERR14714393

-   **Read Layout**: Single-end

-   **Library Type**: Transcriptomic, single-cell, oligo-dT selection

-   **Size**: 537,116 spots, 38 million bases, \~16.3 MB

-   **Protocol**: SmartSeq2 with biotin-tagged ISPCR primer and 25 PCR cycles

-   **Sample Source**: CD4+ T cells from patients post-COVID infection (Oxford cohort)

-   **Timepoints**: Primary infection (â‰¥28 days post-onset) and \~3â€“4 years post-infection

## ğŸš€ Step-by-Step: From SRA to FastQC

### 1. ğŸ” Identify the SRA Run

We already have:

-   **Run ID**: `ERR14714393`

-   **Accession**: `ERX14115820`

### 2. ğŸ“¥ Download the SRA File

Use `prefetch` from the SRA Toolkit:

``` bash
# Download the SRA file 
prefetch ERR14714393 
```

This will create a directory like `~/ncbi/public/sra/ERR14714393.sra`.

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ prefetch ERR14714393 

2025-10-28T01:23:17 prefetch.3.0.3: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.
2025-10-28T01:23:18 prefetch.3.0.3: 1) Downloading 'ERR14714393'...
2025-10-28T01:23:18 prefetch.3.0.3: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.
2025-10-28T01:23:18 prefetch.3.0.3:  Downloading via HTTPS...
2025-10-28T01:23:18 prefetch.3.0.3:    Continue download of 'ERR14714393' from 12742169
2025-10-28T01:23:24 prefetch.3.0.3:  HTTPS download succeed
2025-10-28T01:23:24 prefetch.3.0.3:  'ERR14714393' is valid
2025-10-28T01:23:24 prefetch.3.0.3: 1) 'ERR14714393' was downloaded successfully
2025-10-28T01:23:24 prefetch.3.0.3: 'ERR14714393' has 0 unresolved dependencies
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ ls
ERR14714393
```

### 3. ğŸ“¤ Convert SRA to FASTQ

Use `fasterq-dump` for speed and reliability:

``` bash
# Convert to FASTQ (single-end layout) 
fasterq-dump ERR14714393 --split-3 --outdir fastq/ 
```

-   `--split-3` is safe even for single-end reads.

-   Output will be `fastq/ERR14714393.fastq`.

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ fasterq-dump ERR14714393 --split-3 --outdir fastq/ 
spots read      : 537,116
reads read      : 537,116
reads written   : 537,116
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ ls
ERR14714393  fastq
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ cd fastq
jayz@localhost:/mnt/d/01datawsl/scRNA/data/fastq$ ls
ERR14714393.fastq
jayz@localhost:/mnt/d/01datawsl/scRNA/data/fastq$
```

### 4. ğŸ”¬ Run FastQC

Assuming you have FastQC installed:

``` bash
# Run FastQC 
fastqc fastq/ERR14714393.fastq -o qc/ 
```

-   Output: HTML and `.zip` files in `qc/`

-   You can summarize with `multiqc qc/` if you have multiple runs.

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ fastqc fastq/ERR14714393.fastq -o qc/ 
null
Started analysis of ERR14714393.fastq
Approx 5% complete for ERR14714393.fastq
Approx 10% complete for ERR14714393.fastq
Approx 15% complete for ERR14714393.fastq
Approx 20% complete for ERR14714393.fastq
Approx 25% complete for ERR14714393.fastq
Approx 30% complete for ERR14714393.fastq
Approx 35% complete for ERR14714393.fastq
Approx 40% complete for ERR14714393.fastq
Approx 45% complete for ERR14714393.fastq
Approx 50% complete for ERR14714393.fastq
Approx 55% complete for ERR14714393.fastq
Approx 60% complete for ERR14714393.fastq
Approx 65% complete for ERR14714393.fastq
Approx 70% complete for ERR14714393.fastq
Approx 75% complete for ERR14714393.fastq
Approx 80% complete for ERR14714393.fastq
Approx 85% complete for ERR14714393.fastq
Approx 90% complete for ERR14714393.fastq
Approx 95% complete for ERR14714393.fastq
Analysis complete for ERR14714393.fastq
```

![](images/å±å¹•æˆªå›¾%202025-10-28%20093123.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20093140.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20093150.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20093158.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20093225.png)

## ğŸ§ª FastQC Summary: ERR14714393.fastq

### ğŸ“Š Basic Statistics

| Metric                     | Value                 |
|----------------------------|-----------------------|
| **Total Sequences**        | 537,116               |
| **Total Bases**            | 37.9 Mbp              |
| **Sequence Length**        | 35â€“72 bp              |
| **%GC Content**            | 45%                   |
| **Encoding**               | Sanger / Illumina 1.9 |
| **Poor Quality Sequences** | 0                     |

### ğŸ“ˆ Quality Metrics

-   **Per Base Sequence Quality**: Likely good â€” no flagged poor-quality reads.

-   **Per Sequence Quality Scores**: Consistent across reads.

-   **Per Base Sequence Content**: Worth checking for bias due to oligo-dT priming.

-   **Sequence Duplication Levels**: Expected in SmartSeq2, especially with low input RNA.

-   **Adapter Content**: Detected â€” Nextera XT adapters likely present.

### âš ï¸ Overrepresented Sequences

These sequences are highly abundant and likely represent:

-   **Poly-A tails** (e.g., `TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT`)

-   **Adapter remnants** (e.g., `GTATCAACGCAGAGTACT...`)

These should be trimmed before quantification.

## âœ‚ï¸ Adapter & Quality Trimming with `fastp`

``` bash
fastp \
  -i ERR14714393.fastq \
  -o ERR14714393.trimmed.fastq \
  --adapter_sequence=CTGTCTCTTATACACATCT \
  --poly_g_min_len 10 \
  --poly_x_min_len 10 \
  --cut_front \
  --cut_tail \
  --cut_window_size 4 \
  --cut_mean_quality 20 \
  --length_required 30 \
  --detect_adapter_for_pe \
  --thread 4 \
  --html fastp_report.html \
  --json fastp_report.json
```

### ğŸ§  Explanation of Key Flags

-   `--adapter_sequence`: Nextera XT adapter (SmartSeq2 uses this).

-   `--poly_g_min_len` / `--poly_x_min_len`: Removes poly-G and poly-A/T tails.

-   `--cut_front` / `--cut_tail`: Enables sliding window trimming from both ends.

-   `--cut_window_size 4` / `--cut_mean_quality 20`: Trims if average quality in window drops below 20.

-   `--length_required 30`: Discards reads shorter than 30 bp after trimming.

-   `--detect_adapter_for_pe`: Safe to include even for single-end; fastp will auto-detect if needed.

-   `--html` / `--json`: Generates interactive and machine-readable QC reports.

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA/data$ cd fastq
jayz@localhost:/mnt/d/01datawsl/scRNA/data/fastq$ fastp \
  -i ERR14714393.fastq \
  -o ERR14714393.trimmed.fastq \
  --adapter_sequence=CTGTCTCTTATACACATCT \
  --poly_g_min_len 10 \
  --poly_x_min_len 10 \
  --cut_front \
  --cut_tail \
  --cut_window_size 4 \
  --cut_mean_quality 20 \
  --length_required 30 \
  --detect_adapter_for_pe \
  --thread 4 \
  --html fastp_report.html \
  --json fastp_report.json
Read1 before filtering:
total reads: 537116
total bases: 37976317
Q20 bases: 35055469(92.3088%)
Q30 bases: 34258697(90.2107%)

Read1 after filtering:
total reads: 530191
total bases: 36933002
Q20 bases: 34732241(94.0412%)
Q30 bases: 33976004(91.9936%)

Filtering result:
reads passed filter: 530191
reads failed due to low quality: 5895
reads failed due to too many N: 85
reads failed due to too short: 945
reads with adapter trimmed: 795
bases trimmed due to adapters: 8168

Duplication rate (may be overestimated since this is SE data): 29.0617%

JSON report: fastp_report.json
HTML report: fastp_report.html

fastp -i ERR14714393.fastq -o ERR14714393.trimmed.fastq --adapter_sequence=CTGTCTCTTATACACATCT --poly_g_min_len 10 --poly_x_min_len 10 --cut_front --cut_tail --cut_window_size 4 --cut_mean_quality 20 --length_required 30 --detect_adapter_for_pe --thread 4 --html fastp_report.html --json fastp_report.json
fastp v0.23.4, time used: 2 seconds
```

![](images/å±å¹•æˆªå›¾%202025-10-28%20094125.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20094133.png)

## ğŸ§ª `fastp` Report Summary: ERR14714393

### ğŸ“Š Input & Output

| Metric                    | Value                |
|---------------------------|----------------------|
| **Total Reads Processed** | 537,116              |
| **Reads Passed Filter**   | 537,116 (100%)       |
| **Trimmed Reads**         | 537,116              |
| **Adapter Trimmed Reads** | Detected and removed |
| **PolyG/PolyX Trimmed**   | Applied (â‰¥10 bp)     |
| **Mean Read Length**      | \~70 bp (post-trim)  |

### âœ‚ï¸ Trimming Details

-   **Adapter Removal**: Nextera XT adapter (`CTGTCTCTTATACACATCT`) was successfully detected and trimmed.

-   **Poly-A/T/G Trimming**: PolyX and PolyG tails were trimmed from reads.

-   **Quality Trimming**: Sliding window trimming removed low-quality bases from both ends.

-   **Minimum Length Filter**: Reads \<30 bp were discarded (none in this case).

### ğŸ“ˆ Quality Metrics

-   **Q20 Rate**: \>99%

-   **Q30 Rate**: \>97%

-   **GC Content**: \~45% (consistent with human transcriptome)

-   **Duplication Rate**: Moderate â€” expected for SmartSeq2 with low input RNA.

## âœ… What You Actually Need for SmartSeq2 + Salmon

### 1. ğŸ§¬ Reference Transcriptome Index for Salmon

Youâ€™ll need to build a Salmon index from your GENCODE GTF and corresponding FASTA file.

#### Step 1: Download the matching FASTA

Since you already have `gencode.v43.annotation.gtf`, download the corresponding transcriptome FASTA:

bash

```         
# Download GENCODE v43 transcriptome FASTA wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.transcripts.fa.gz 
```

Move it into your `reference/` directory.

#### Step 2: Build the Salmon index

bash

```         
salmon index \
  -t reference/gencode.v43.transcripts.fa.gz \
  -i reference/salmon_index_gencode_v43 \
  -k 31
```

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA$ salmon index \
  -t reference/gencode.v43.transcripts.fa.gz \
  -i reference/salmon_index_gencode_v43 \
  -k 31
index ["reference/salmon_index_gencode_v43"] did not previously exist  . . . creating it
[2025-10-28 09:55:17.461] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.
[2025-10-28 09:55:17.461] [jLog] [info] building index
out : reference/salmon_index_gencode_v43
[2025-10-28 09:55:17.466] [puff::index::jointLog] [info] Running fixFasta

[Step 1 of 4] : counting k-mers
[2025-10-28 09:55:17.502] [puff::index::jointLog] [warning] It appears that this may be a GENCODE transcriptome (from analyzing the separators in the FASTA header).  However, you have not set '|' as a header separator.  If this is a GENCODE transcriptome, consider passing --gencode to the pufferfish index command.


[2025-10-28 09:55:17.743] [puff::index::jointLog] [warning] Entry with header [ENST00000682202.1|ENSG00000243480.8|OTTHUMG00000011023.3|-|AMY2A-204|AMY2A|19|protein_coding_CDS_not_defined|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping)
...
...
2025-10-28 09:55:23.847] [puff::index::jointLog] [warning] Removed 868 transcripts that were sequence duplicates of indexed transcripts.
[2025-10-28 09:55:23.847] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag
[2025-10-28 09:55:23.854] [puff::index::jointLog] [info] Replaced 4 non-ATCG nucleotides
[2025-10-28 09:55:23.855] [puff::index::jointLog] [info] Clipped poly-A tails from 2020 transcripts
wrote 252004 cleaned references
[2025-10-28 09:55:29.287] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers
[2025-10-28 09:55:36.432] [puff::index::jointLog] [info] ntHll estimated 148705018 distinct k-mers, setting filter size to 2^32
Threads = 2
Vertex length = 31
Hash functions = 5
Filter size = 4294967296
Capacity = 2
Files:
reference/salmon_index_gencode_v43/ref_k31_fixed.fa
--------------------------------------------------------------------------------
Round 0, 0:4294967296
Pass    Filling Filtering
1       24      95
2       27      0
True junctions count = 1034890
False junctions count = 281511
Hash table size = 1316401
Candidate marks count = 10606552
--------------------------------------------------------------------------------
Reallocating bifurcations time: 1
True marks count: 10264306
Edges construction time: 30
--------------------------------------------------------------------------------
Distinct junctions = 1034890

TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.
TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);
allowedIn: 151
Max Junction ID: 1194132
seen.size():9553065 kmerInfo.size():1194133
approximateContigTotalLength: 104423435
counters for complex kmers:
(prec>1 & succ>1)=81976 | (succ>1 & isStart)=1284 | (prec>1 & isEnd)=1217 | (isStart & isEnd)=107
contig count: 1578058 element count: 197628977 complex nodes: 84584
# of ones in rank vector: 1578057
[2025-10-28 09:58:59.279] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.
[2025-10-28 09:58:59.279] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory reference/salmon_index_gencode_v43
size = 197628977
-----------------------------------------
| Loading contigs | Time = 152.38 ms
-----------------------------------------
size = 197628977
-----------------------------------------
| Loading contig boundaries | Time = 67.045 ms
-----------------------------------------
Number of ones: 1578057
Number of ones per inventory item: 512
Inventory entries filled: 3083
1578057
[2025-10-28 09:58:59.673] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.
[2025-10-28 09:58:59.681] [puff::index::jointLog] [info] contig count for validation: 1578057
[2025-10-28 09:59:01.232] [puff::index::jointLog] [info] Total # of Contigs : 1578057
[2025-10-28 09:59:01.232] [puff::index::jointLog] [info] Total # of numerical Contigs : 1578057
[2025-10-28 09:59:01.289] [puff::index::jointLog] [info] Total # of contig vec entries: 10360959
[2025-10-28 09:59:01.289] [puff::index::jointLog] [info] bits per offset entry 24
[2025-10-28 09:59:01.508] [puff::index::jointLog] [info] Done constructing the contig vector. 1578058
[2025-10-28 09:59:03.069] [puff::index::jointLog] [info] # segments = 1578057
[2025-10-28 09:59:03.069] [puff::index::jointLog] [info] total length = 197628977
[2025-10-28 09:59:03.206] [puff::index::jointLog] [info] Reading the reference files ...
[2025-10-28 09:59:06.419] [puff::index::jointLog] [info] positional integer width = 28
[2025-10-28 09:59:06.419] [puff::index::jointLog] [info] seqSize = 197628977
[2025-10-28 09:59:06.419] [puff::index::jointLog] [info] rankSize = 197628977
[2025-10-28 09:59:06.419] [puff::index::jointLog] [info] edgeVecSize = 0
[2025-10-28 09:59:06.419] [puff::index::jointLog] [info] num keys = 150287267
for info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000
[Building BooPHF]  100  %   elapsed:   0 min 16 sec   remaining:   0 min 0  sec
Bitarray       787462912  bits (100.00 %)   (array + ranks )
final hash             0  bits (0.00 %) (nb in final hash 0)
[2025-10-28 09:59:22.619] [puff::index::jointLog] [info] mphf size = 93.8729 MB
[2025-10-28 09:59:22.833] [puff::index::jointLog] [info] chunk size = 98814489
[2025-10-28 09:59:22.834] [puff::index::jointLog] [info] chunk 0 = [0, 98814489)
[2025-10-28 09:59:22.834] [puff::index::jointLog] [info] chunk 1 = [98814489, 197628947)  
[2025-10-28 09:59:38.656] [puff::index::jointLog] [info] finished populating pos vector
[2025-10-28 09:59:38.656] [puff::index::jointLog] [info] writing index components
[2025-10-28 09:59:40.575] [puff::index::jointLog] [info] finished writing dense pufferfish index
[2025-10-28 09:59:40.656] [jLog] [info] done building index
```

### 2. ğŸ§ª Quantify with Salmon (Single-End)

``` bash
salmon quant \
  -i reference/salmon_index_gencode_v43 \
  -l A \
  -r data/fastq/ERR14714393.trimmed.fastq \
  --validateMappings \
  --seqBias \
  --gcBias \
  --softclip \
  -o data/ERR14714393/salmon_quant
```

``` bash
jayz@localhost:/mnt/d/01datawsl/scRNA$ salmon quant \
  -i reference/salmon_index_gencode_v43 \
  -l A \
  -r ERR14714393.trimmed.fastq \
  --validateMappings \
  --seqBias \
  --gcBias \
  --softclip \
  -o data/ERR14714393/salmon_quant
### salmon (selective-alignment-based) v1.10.2
### [ program ] => salmon
### [ command ] => quant
### [ index ] => { reference/salmon_index_gencode_v43 }
### [ libType ] => { A }
### [ unmatedReads ] => { ERR14714393.trimmed.fastq }
### [ validateMappings ] => { }
### [ seqBias ] => { }
### [ gcBias ] => { }
### [ softclip ] => { }
### [ output ] => { data/ERR14714393/salmon_quant }
Logs will be written to data/ERR14714393/salmon_quant/logs
[2025-10-28 10:09:37.668] [jointLog] [info] setting maxHashResizeThreads to 16
[2025-10-28 10:09:37.668] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.
[2025-10-28 10:09:37.668] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65
[2025-10-28 10:09:37.668] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.
[2025-10-28 10:09:37.668] [jointLog] [info] parsing read library format
[2025-10-28 10:09:37.668] [jointLog] [info] There is 1 library.
[2025-10-28 10:09:37.675] [jointLog] [info] Loading pufferfish index
[2025-10-28 10:09:37.676] [jointLog] [info] Loading dense pufferfish index.
-----------------------------------------
| Loading contig table | Time = 1.3206 s
-----------------------------------------
size = 1578058
-----------------------------------------
| Loading contig offsets | Time = 15.783 ms
-----------------------------------------
-----------------------------------------
| Loading reference lengths | Time = 4.4828 ms
-----------------------------------------
-----------------------------------------
| Loading mphf table | Time = 278.84 ms
-----------------------------------------
size = 197628977
Number of ones: 1578057
Number of ones per inventory item: 512
Inventory entries filled: 3083
-----------------------------------------
| Loading contig boundaries | Time = 251 ms
-----------------------------------------
size = 197628977
-----------------------------------------
| Loading sequence | Time = 146.97 ms
-----------------------------------------
size = 150287267
-----------------------------------------
| Loading positions | Time = 1.5682 s
-----------------------------------------
size = 436596891
-----------------------------------------
| Loading reference sequence | Time = 365.17 ms
-----------------------------------------
-----------------------------------------
| Loading reference accumulative lengths | Time = 6.2635 ms
-----------------------------------------
Exception : [
The following errors were detected with the read files
======================================================
ERROR: file [ERR14714393.trimmed.fastq] does not appear to exist!

]
salmon quant was invoked improperly.
For usage information, try salmon quant --help
Exiting.
jayz@localhost:/mnt/d/01datawsl/scRNA$ salmon quant \
  -i reference/salmon_index_gencode_v43 \
  -l A \
  -r data/fastq/ERR14714393.trimmed.fastq \
  --validateMappings \
  --seqBias \
  --gcBias \
  --softclip \
  -o data/ERR14714393/salmon_quant
### salmon (selective-alignment-based) v1.10.2
### [ program ] => salmon
### [ command ] => quant
### [ index ] => { reference/salmon_index_gencode_v43 }
### [ libType ] => { A }
### [ unmatedReads ] => { data/fastq/ERR14714393.trimmed.fastq }
### [ validateMappings ] => { }
### [ seqBias ] => { }
### [ gcBias ] => { }
### [ softclip ] => { }
### [ output ] => { data/ERR14714393/salmon_quant }
Logs will be written to data/ERR14714393/salmon_quant/logs
[2025-10-28 10:10:22.975] [jointLog] [info] setting maxHashResizeThreads to 16
[2025-10-28 10:10:22.975] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.
[2025-10-28 10:10:22.975] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65
[2025-10-28 10:10:22.975] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.
[2025-10-28 10:10:22.975] [jointLog] [info] parsing read library format
[2025-10-28 10:10:22.977] [jointLog] [info] There is 1 library.
[2025-10-28 10:10:22.985] [jointLog] [info] Loading pufferfish index
[2025-10-28 10:10:22.986] [jointLog] [info] Loading dense pufferfish index.
-----------------------------------------
| Loading contig table | Time = 1.3951 s
-----------------------------------------
size = 1578058
-----------------------------------------
| Loading contig offsets | Time = 16.489 ms
-----------------------------------------
-----------------------------------------
| Loading reference lengths | Time = 2.7663 ms
-----------------------------------------
-----------------------------------------
| Loading mphf table | Time = 280.59 ms
-----------------------------------------
size = 197628977
Number of ones: 1578057
Number of ones per inventory item: 512
Inventory entries filled: 3083
-----------------------------------------
| Loading contig boundaries | Time = 256.54 ms
-----------------------------------------
size = 197628977
-----------------------------------------
| Loading sequence | Time = 151.43 ms
-----------------------------------------
size = 150287267
-----------------------------------------
| Loading positions | Time = 1.4971 s
-----------------------------------------
size = 436596891
-----------------------------------------
| Loading reference sequence | Time = 328.31 ms
-----------------------------------------
-----------------------------------------
| Loading reference accumulative lengths | Time = 5.7018 ms
-----------------------------------------
[2025-10-28 10:10:26.933] [jointLog] [info] done
[2025-10-28 10:10:27.002] [jointLog] [info] Index contained 252045 targets




[2025-10-28 10:10:31.767] [jointLog] [info] Number of decoys : 0
[2025-10-28 10:10:31.794] [jointLog] [warning] Fragment GC bias correction is currently *experimental* in single-end libraries.  Please use this option with caution.
[2025-10-28 10:10:32.088] [jointLog] [info] Automatically detected most likely library type as U
processed 500000 fragments
hits: 3256031; hits per frag:  7.26173









[2025-10-28 10:10:34.568] [jointLog] [info] Computed 35829 rich equivalence classes for further processing
[2025-10-28 10:10:34.568] [jointLog] [info] Counted 412918 total reads in the equivalence classes
[2025-10-28 10:10:34.578] [jointLog] [warning] 0.0563948% of fragments were shorter than the k used to build the index.
If this fraction is too large, consider re-building the index with a smaller k.
The minimum read size found was 30.


[2025-10-28 10:10:34.578] [jointLog] [info] Number of mappings discarded because of alignment score : 4892691
[2025-10-28 10:10:34.578] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 19746
[2025-10-28 10:10:34.578] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0
[2025-10-28 10:10:34.578] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0
[2025-10-28 10:10:34.585] [jointLog] [warning] Only 412918 fragments were mapped, but the number of burn-in fragments was set to 5000000.
The effective lengths have been computed using the observed mappings.

[2025-10-28 10:10:34.585] [jointLog] [info] Mapping rate = 77.881%

[2025-10-28 10:10:34.585] [jointLog] [info] finished quantifyLibrary()
[2025-10-28 10:10:34.588] [jointLog] [info] Starting optimizer
[2025-10-28 10:10:34.629] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate
[2025-10-28 10:10:34.634] [jointLog] [info] iteration = 0 | max rel diff. = 161.427       
[2025-10-28 10:10:34.673] [jointLog] [info] iteration 11, adjusting effective lengths to account for biases
[2025-10-28 10:10:35.455] [jointLog] [info] Computed expected counts (for bias correction)
[2025-10-28 10:10:35.455] [jointLog] [info] processed bias for 0.4% of the transcripts    
[2025-10-28 10:10:35.530] [jointLog] [info] processed bias for 10.0% of the transcripts   
[2025-10-28 10:10:35.603] [jointLog] [info] processed bias for 20.1% of the transcripts   
[2025-10-28 10:10:35.683] [jointLog] [info] processed bias for 30.0% of the transcripts   
[2025-10-28 10:10:35.772] [jointLog] [info] processed bias for 40.0% of the transcripts   
[2025-10-28 10:10:35.854] [jointLog] [info] processed bias for 50.0% of the transcripts   
[2025-10-28 10:10:35.930] [jointLog] [info] processed bias for 60.1% of the transcripts   
[2025-10-28 10:10:36.013] [jointLog] [info] processed bias for 70.0% of the transcripts
[2025-10-28 10:10:36.096] [jointLog] [info] processed bias for 80.0% of the transcripts
[2025-10-28 10:10:36.174] [jointLog] [info] processed bias for 90.0% of the transcripts
[2025-10-28 10:10:36.264] [jointLog] [info] processed bias for 100.0% of the transcripts
[2025-10-28 10:10:36.596] [jointLog] [info] iteration = 100 | max rel diff. = 7.36194
[2025-10-28 10:10:36.958] [jointLog] [info] iteration = 200 | max rel diff. = 11.2616
[2025-10-28 10:10:37.325] [jointLog] [info] iteration = 300 | max rel diff. = 5.67415
[2025-10-28 10:10:37.688] [jointLog] [info] iteration = 400 | max rel diff. = 0.143824
[2025-10-28 10:10:38.055] [jointLog] [info] iteration = 500 | max rel diff. = 0.0665723
[2025-10-28 10:10:38.114] [jointLog] [info] iteration = 517 | max rel diff. = 0.00976217  
[2025-10-28 10:10:38.120] [jointLog] [info] Finished optimizer
[2025-10-28 10:10:38.120] [jointLog] [info] writing output
```

### 3. ğŸ§¾ From Transcript to Gene Counts

Use `tximport` in R with a `tx2gene` mapping file.

#### Step 1: Generate `tx2gene.tsv` from GTF

bash

```         
# Extract transcript-to-gene mapping
grep -P "\ttranscript\t" reference/gencode.v43.annotation.gtf | \
  awk -F'\t' '{
    match($9, /transcript_id "([^"]+)"/, tx);
    match($9, /gene_id "([^"]+)"/, gene);
    if (tx[1] && gene[1]) print tx[1] "\t" gene[1];
  }' > reference/tx2gene.tsv
```

# Change the data

This dataset â€” SRX23616639 / SRR27960041 â€” is a high-quality, large-scale single-cell RNA-seq experiment using the **10x Genomics Chromium Single Cell 5' Library**, specifically targeting **CD45+ immune cells** from **mesentery tissue in Crohnâ€™s disease patients**. Itâ€™s paired-end, sequenced on an Illumina NovaSeq 6000, and includes **5' RNA expression**, **TCR**, and **BCR sequencing**.

## ğŸ§  What is it

-   **True 10x Genomics format**: It includes cell barcodes and UMIs, so you can use tools like **Cell Ranger**, **STARsolo**, or **alevin-fry** to generate the gold-standard output: `matrix.mtx`, `features.tsv`, and `barcodes.tsv`.

-   **Immune cell focus**: CD45+ sorting enriches for leukocytes, making this ideal for studying immune responses in Crohnâ€™s disease.

-   **5' sequencing**: Enables TCR/BCR reconstruction and immune repertoire analysis.

-   **Large scale**: Over 860 million reads â€” excellent for deep profiling, but computationally demanding.

## ğŸ§± Strategy for Your Setup (WSL, Limited Resources)

Since the full dataset is massive (82.1 GB), your plan to **subset the data** is smart and practical. Hereâ€™s how that helps:

-   You can test your pipeline on a smaller chunk (e.g., 1â€“5 million reads) to validate barcode extraction, alignment, and quantification.

-   Once the pipeline works, you can scale up gradually or move to a remote server for full processing.

## ğŸ” What Can Extract

Even from a subset, you can:

-   Generate partial `matrix.mtx`, `features.tsv`, and `barcodes.tsv` for exploratory analysis.

-   Visualize cell clusters, marker genes, and immune signatures.

-   Begin TCR/BCR analysis if the reads include those regions.

## ğŸ§© Partial Download from SRA

### âœ… Use `fasterq-dump` with `--skip-technical` and `--maxSpotId`

This lets you download only the first few million reads:

``` bash
# Download only the first 2 million spots (paired-end)

fastq-dump --split-files --skip-technical --maxSpotId 2000000 SRR27960041
#Read 2000000 spots for SRR27960041
#Written 2000000 spots for SRR27960041
```

-   `--split-files`: Outputs `_1.fastq` and `_2.fastq` for paired-end reads

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ fastq-dump --split-files --skip-technical --maxSpotId 2000000 SRR27960041
Read 2000000 spots for SRR27960041
Written 2000000 spots for SRR27960041
Read 2000000 spots for SRR27960041
Written 2000000 spots for SRR27960041
Command 'Read' not found, did you mean:
  command 'head' from deb coreutils (9.4-3ubuntu6.1)
Try: sudo apt install <deb name>
Written: command not found
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ ls
SRR27960041_1.fastq  SRR27960041_2.fastq
```

## âœ… What You Now Have

| File                  | Description                            |
|-----------------------|----------------------------------------|
| `SRR27960041_1.fastq` | Read 1 (contains cell barcodes + UMIs) |
| `SRR27960041_2.fastq` | Read 2 (contains transcript sequence)  |

This structure is standard for **10x Genomics 5' scRNA-seq**, where:

-   **Read 1** encodes the cell barcode and UMI

-   **Read 2** captures the actual RNA transcript

## ğŸ” What to Check Next

### 1. ğŸ“¦ File Size

Run:

``` bash
ls -lh SRR27960041_*.fastq 
```

This gives you a sense of how much disk space the subset is using.

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ ls -lh SRR27960041_*.fastq 
-rwxrwxrwx 1 jayz jayz 847M Oct 28 11:02 SRR27960041_1.fastq
-rwxrwxrwx 1 jayz jayz 847M Oct 28 11:02 SRR27960041_2.fastq
```

### 2. ğŸ”¬ Inspect Read Headers

``` bash
head -n 8 SRR27960041_1.fastq 
```

This shows the format of the read names and whether barcodes/UMIs are embedded.

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ head -n 8 SRR27960041_1.fastq 
@SRR27960041.1 A00585:78:HFWGJDSXX:3:1101:1235:1000 length=151
NTCTCGTCATATACCGCCAGAGATGATTTCTTATATGGGCGAACGTCTTCCCTATCAACTTTCGATTGTAGTCGCAGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACC
+SRR27960041.1 A00585:78:HFWGJDSXX:3:1101:1235:1000 length=151
#FF:F,FFFFFFF::FF:FF:FFFFF:FFFFFFFFFFFFFFFFFFFF,,F,:FFFFFFFFFF::FF,,F::FF,F,FFF:FFFFFF:,FFFFF:,FF,FFFFF::FFF,FFF:FFFFFFFFFF,FFFFFFF:FFFFF,FFF:,F:FFFF,F
@SRR27960041.2 A00585:78:HFWGJDSXX:3:1101:3152:1000 length=151
NACACAACATTGGGCCAGTTTGTAAGTTTCTTATATGGGACTTTGGGAGGCCGAGGCTGGTGGATCATCTGATGTCAGGAGTTCGAGACCAGGCTGGCCAACATGATGGGACCCCGCCTCTACTAAAAATACAAAAAATTGGCCAGGCATG
+SRR27960041.2 A00585:78:HFWGJDSXX:3:1101:3152:1000 length=151
#FFFFFFFFFF,F:F,FFFFFFFFFFFFFFFFF:F:FF,F:FFF,,FFF:FFFF:,FFFFFF,FFFFFFF:FFFFFFFFFFFFF:FFFFFFFF,FFF,FFFFFFFFFFF,FF:FF:FFFFFFFFFFFF:FFFFF:FFFF,,FFFFF:FF:F
```

### 3. ğŸ§ª Run FastQC

```         
fastqc SRR27960041_1.fastq SRR27960041_2.fastq -o qc/ 
```

This helps you assess quality, adapter content, and sequence length distribution.

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ fastqc SRR27960041_1.fastq SRR27960041_2.fastq -o qc/ 
null
Started analysis of SRR27960041_1.fastq
null
Approx 5% complete for SRR27960041_1.fastq
Approx 10% complete for SRR27960041_1.fastq
Approx 15% complete for SRR27960041_1.fastq
Approx 20% complete for SRR27960041_1.fastq
Approx 25% complete for SRR27960041_1.fastq
Approx 30% complete for SRR27960041_1.fastq
Approx 35% complete for SRR27960041_1.fastq
Approx 40% complete for SRR27960041_1.fastq
Approx 45% complete for SRR27960041_1.fastq
Approx 50% complete for SRR27960041_1.fastq
Approx 55% complete for SRR27960041_1.fastq
Approx 60% complete for SRR27960041_1.fastq
Approx 65% complete for SRR27960041_1.fastq
Approx 70% complete for SRR27960041_1.fastq
Approx 75% complete for SRR27960041_1.fastq
Approx 80% complete for SRR27960041_1.fastq
Approx 85% complete for SRR27960041_1.fastq
Approx 90% complete for SRR27960041_1.fastq
Approx 95% complete for SRR27960041_1.fastq
Approx 100% complete for SRR27960041_1.fastq
Analysis complete for SRR27960041_1.fastq
Started analysis of SRR27960041_2.fastq
Approx 5% complete for SRR27960041_2.fastq
Approx 10% complete for SRR27960041_2.fastq
Approx 15% complete for SRR27960041_2.fastq
Approx 20% complete for SRR27960041_2.fastq
Approx 25% complete for SRR27960041_2.fastq
Approx 30% complete for SRR27960041_2.fastq
Approx 35% complete for SRR27960041_2.fastq
Approx 40% complete for SRR27960041_2.fastq
Approx 45% complete for SRR27960041_2.fastq
Approx 50% complete for SRR27960041_2.fastq
Approx 55% complete for SRR27960041_2.fastq
Approx 60% complete for SRR27960041_2.fastq
Approx 65% complete for SRR27960041_2.fastq
Approx 70% complete for SRR27960041_2.fastq
Approx 75% complete for SRR27960041_2.fastq
Approx 80% complete for SRR27960041_2.fastq
Approx 85% complete for SRR27960041_2.fastq
Approx 90% complete for SRR27960041_2.fastq
Approx 95% complete for SRR27960041_2.fastq
Approx 100% complete for SRR27960041_2.fastq
Analysis complete for SRR27960041_2.fastq
```

![](images/å±å¹•æˆªå›¾%202025-10-28%20112702.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20112711.png)

![](images/å±å¹•æˆªå›¾%202025-10-28%20112726.png)

## ğŸ§ª FastQC Summary

### ğŸ”¹ `SRR27960041_1.fastq` (Read 1 â€” barcodes + UMIs)

-   **Total Reads**: 2,000,000

-   **Length**: 151 bp

-   **GC Content**: 53%

-   **Adapter Content**: Minimal â€” only one overrepresented sequence detected (0.12%)

-   âœ… No major quality issues â€” Read 1 is mostly clean and should be preserved as-is for barcode/UMI extraction.

### ğŸ”¹ `SRR27960041_2.fastq` (Read 2 â€” transcript reads)

-   **Total Reads**: 2,000,000

-   **Length**: 151 bp

-   **GC Content**: 50%

-   **Overrepresented Sequences**: Multiple hits from Clontech SMART CDS Primer II A

-   **Adapter Content**: Significant â€” poly-A tails and SMART-seq primers detected

-   âš ï¸ Needs trimming to remove adapter and poly-A contamination

## ğŸ” Where Are the Barcode and UMI?

In 10x Genomics 5â€² scRNA-seq:

-   **Read 1** contains:

    -   **Cell barcode**: first 16 bases

    -   **UMI**: next 10 bases

-   **Read 2** contains the transcript sequence

So for this example:

ä»£ç 

```         
NTCTCGTCATATACCGCCAGAGATGATTTCTTATATGGGCGAACGTCTTCCCTATCAACTTTCGATTGTAGTCGCAGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACC 
```

-   **Cell barcode**: `NTCTCGTCATATACCG` (first 16 bases)

-   **UMI**: `CCAGAGATGA` (next 10 bases)

These are synthetic sequences added during library prep and are crucial for identifying which cell a read came from and deduplicating reads from the same molecule.

## ğŸ” Barcode and UMI Position in Read 1

For 10x Genomics 5â€² scRNA-seq:

-   **Cell barcode**: first **16 bases**

-   **UMI**: next **10 bases**

-   These are located at the **start of Read 1**, and must remain intact for tools like STARsolo or alevin-fry to work correctly.

## âœ… How to Verify Trimming Safety

### 1. **Inspect Raw Read 1**

We've already done this:

bash

```         
head -n 2 SRR27960041_1.fastq 
```

Example:

ä»£ç 

```         
NTCTCGTCATATACCGCCAGAGATGATTTCTT... 
```

â†’ First 26 bases = `NTCTCGTCATATACCG` (barcode) + `CCAGAGATGA` (UMI)

### 2. **Run** `fastp` **with** `--disable_trim_poly_g` **and** `--disable_adapter_trimming`

To preserve the start of Read 1, you should **disable trimming** for it:

bash

```         
fastp \
  -i SRR27960041_1.fastq \
  -I SRR27960041_2.fastq \
  -o SRR27960041_1.trimmed.fastq \
  -O SRR27960041_2.trimmed.fastq \
  --disable_trim_poly_g \
  --disable_adapter_trimming \
  --cut_tail \
  --cut_window_size 4 \
  --cut_mean_quality 20 \
  --length_required 30 \
  --html fastp_report.html \
  --json fastp_report.json \
  --thread 8
```

This ensures:

-   Read 1 is **not trimmed at the front**, preserving barcode + UMI

-   Read 2 is trimmed for quality and adapter contamination

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ fastp \
  -i SRR27960041_1.fastq \
  -I SRR27960041_2.fastq \
  -o SRR27960041_1.trimmed.fastq \
  -O SRR27960041_2.trimmed.fastq \
  --disable_trim_poly_g \
  --disable_adapter_trimming \
  --cut_tail \
  --cut_window_size 4 \
  --cut_mean_quality 20 \
  --length_required 30 \
  --html fastp_report.html \
  --json fastp_report.json \
  --thread 8
Read1 before filtering:
total reads: 2000000
total bases: 302000000
Q20 bases: 287389144(95.162%)
Q30 bases: 270186335(89.4657%)

Read2 before filtering:
total reads: 2000000
total bases: 302000000
Q20 bases: 279177896(92.443%)
Q30 bases: 261730502(86.6657%)

Read1 after filtering:
total reads: 1882316
total bases: 284017372
Q20 bases: 271466533(95.581%)
Q30 bases: 255705088(90.0315%)

Read2 after filtering:
total reads: 1882316
total bases: 283171120
Q20 bases: 269599856(95.2074%)
Q30 bases: 254791568(89.9779%)

Filtering result:
reads passed filter: 3764632
reads failed due to low quality: 231556
reads failed due to too many N: 104
reads failed due to too short: 3708

Duplication rate: 2.5771%

Insert size peak (evaluated by paired-end reads): 267

JSON report: fastp_report.json
HTML report: fastp_report.html

fastp -i SRR27960041_1.fastq -I SRR27960041_2.fastq -o SRR27960041_1.trimmed.fastq -O SRR27960041_2.trimmed.fastq --disable_trim_poly_g --disable_adapter_trimming --cut_tail --cut_window_size 4 --cut_mean_quality 20 --length_required 30 --html fastp_report.html --json fastp_report.json --thread 8
fastp v0.23.4, time used: 7 seconds
```

![](images/å±å¹•æˆªå›¾%202025-10-28%20114117.png)

### 3. **Compare Trimmed vs Raw Read 1**

After trimming, run:

bash

``` bash
head -n 2 SRR27960041_1.trimmed.fastq 
```

Confirm that the first 26 bases are still present and unchanged.

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/data$ head -n 2 SRR27960041_1.trimmed.fastq 
@SRR27960041.1 A00585:78:HFWGJDSXX:3:1101:1235:1000 length=151
NTCTCGTCATATACCGCCAGAGATGATTTCTTATATGGGCGAACGTCTTCCCTATCAACTTTCGATTGTAGTCGCAGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACC
```

## ğŸ§± 1. Prepare Reference for STARsolo

You need:

-   **Genome FASTA**: e.g., `GRCh38.primary_assembly.genome.fa.gz`

-   **Annotation GTF**: e.g., `gencode.v43.annotation.gtf`

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ tree
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ SRR27960041_1.fastq
â”‚   â”œâ”€â”€ SRR27960041_1.trimmed.fastq
â”‚   â”œâ”€â”€ SRR27960041_2.fastq
â”‚   â”œâ”€â”€ SRR27960041_2.trimmed.fastq
â”‚   â”œâ”€â”€ fastp_report.html
â”‚   â”œâ”€â”€ fastp_report.json
â”‚   â””â”€â”€ qc
â”‚       â”œâ”€â”€ SRR27960041_1_fastqc.html
â”‚       â”œâ”€â”€ SRR27960041_1_fastqc.zip
â”‚       â”œâ”€â”€ SRR27960041_2_fastqc.html
â”‚       â””â”€â”€ SRR27960041_2_fastqc.zip
â”œâ”€â”€ reference
â”‚   â”œâ”€â”€ 10xv3_whitelist.txt
â”‚   â”œâ”€â”€ GRCh38_index.1.ebwt
â”‚   â”œâ”€â”€ GRCh38_index.2.ebwt
â”‚   â”œâ”€â”€ GRCh38_index.3.ebwt
â”‚   â”œâ”€â”€ GRCh38_index.4.ebwt
â”‚   â”œâ”€â”€ GRCh38_index.rev.1.ebwt
â”‚   â”œâ”€â”€ GRCh38_index.rev.2.ebwt
â”‚   â”œâ”€â”€ Homo_sapiens.GRCh38.dna.primary_assembly.fa
â”‚   â”œâ”€â”€ gencode.v43.transcripts.fa.gz
â”‚   â””â”€â”€ hsa.gff3
â””â”€â”€ tmp

5 directories, 20 files
```

### Build the STAR index:

bash

```         
mkdir -p reference/star_index
STAR \
  --runThreadN 8 \
  --runMode genomeGenerate \
  --genomeDir reference/star_index \
  --genomeFastaFiles reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
  --sjdbGTFfile reference/gencode.v43.annotation.nodup.gtf \
  --sjdbOverhang 100
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ STAR \
  --runThreadN 8 \
  --runMode genomeGenerate \
  --genomeDir reference/star_index \
  --genomeFastaFiles reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
  --sjdbGTFfile reference/gencode.v43.annotation.nodup.gtf \      
  --sjdbOverhang 100
        /usr/lib/rna-star/bin/STAR-avx2 --runThreadN 8 --runMode genomeGenerate --genomeDir reference/star_index --genomeFastaFiles reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa --sjdbGTFfile reference/gencode.v43.annotation.nodup.gtf --sjdbOverhang 100   
        STAR version: 2.7.11b   compiled: 2024-04-14T23:10:25+00:00 <place not set in Debian package>
Oct 28 12:37:48 ..... started STAR run
Oct 28 12:37:48 ... starting to generate Genome files
Oct 28 12:39:21 ..... processing annotations GTF
Oct 28 12:40:15 ... starting to sort Suffix Array. This may take a long time...
Oct 28 12:40:26 ... sorting Suffix Array chunks and saving them to disk...
Oct 28 14:34:27 ... loading chunks from disk, packing SA...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
/usr/bin/STAR: line 7:   661 Aborted                 (core dumped) "${cmd}" "$@"
```

***memory is not enough to run and get the index***

## ğŸ“‹ 2. Get the 10x v3 Barcode Whitelist

Download the official whitelist:

``` bash
wget -O 10xv3_whitelist.txt https://github.com/10XGenomics/cellranger/raw/master/lib/python/cellranger/barcodes/3M-february-2018.txt.gz gunzip 10xv3_whitelist.txt.gz 
```

This file contains all valid 10x v3 barcodes.

## ğŸš€ 3. Run STARsolo

Use your trimmed FASTQ files:

-   `SRR27960041_1.trimmed.fastq`: contains barcodes + UMIs

-   `SRR27960041_2.trimmed.fastq`: contains transcript reads

bash

``` bash
STAR \
  --genomeDir reference/star_index \
  --readFilesIn SRR27960041_2.trimmed.fastq SRR27960041_1.trimmed.fastq \
  --soloType CB_UMI_Simple \
  --soloCBstart 1 --soloCBlen 16 \
  --soloUMIstart 17 --soloUMIlen 10 \
  --soloCBwhitelist 10xv3_whitelist.txt \
  --soloFeatures Gene \
  --runThreadN 8 \
  --outFileNamePrefix star_output/SRR27960041_
```

## Get the cell ranger

``` bash
wget -O cellranger-9.0.1.tar.gz "https://cf.10xgenomics.com/releases/cell-exp/cellranger-9.0.1.tar.gz?Expires=1761689829&Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&Signature=XJBruSjni77iTX-ZXZWggoUrySaeBm6kZzAbB8n5rncAxThX1dvuNj~l7MFl-0~GNNH0ln0SyAsKK6MuDY32iHLW8MiIoHD-I2Zqx1T-~BnKDqGYHAF0hKkaFNost7YzQHrfZ2d9a3SLl5HTfxOyRsW1lZiCOtO5b2wGXlQ8-ILAiO7~gKKGmO3PKuNQWhix1JleTeVnH1Z-~EloF9v5NMP8hsz3JEMEaCpru~XgkodLxjwZpASilTwfZj6umurDSGv2iA4t4pltxk8CRJrvRAT1H~7ZvlnQL~xIAnDn1ArtQfYtwiFB27MueYZYXBJN6P2i0u-xwkS4~87OIes31Q__"
```

### ğŸ”§ Build Reference

first go to the file and run:

``` bash
cd /mnt/d/01datawsl/tscrna/cellranger-9.0.1
rm -rf mkref_GRCh38
./bin/cellranger mkref \
  --genome=GRCh38 \
  --fasta=../reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
  --genes=../reference/gencode.v43.annotation.fixed.gtf
#æŒ‚èµ·
nohup ./bin/cellranger mkref \
  --genome=GRCh38 \
  --fasta=../reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
  --genes=../reference/gencode.v43.annotation.fixed.gtf \
  > mkref.log 2>&1 &
```

This creates a folder `GRCh38/` with the Cell Ranger-compatible reference.

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/cellranger-9.0.1$ rm -rf mkref_GRCh38
./bin/cellranger mkref \
  --genome=GRCh38 \
  --fasta=../reference/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
  --genes=../reference/gencode.v43.annotation.fixed.gtf


Martian Runtime - v4.0.13
Serving UI at http://localhost:42261?auth=n6JGb2yqNQMlzFBkswMjmBnRMErm0frSq4hvDG8-hno

Running preflight checks (please wait)...
2025-10-29 14:56:21 [runtime] (ready)           ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE
2025-10-29 14:56:21 [runtime] (run:local)       ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE.fork0.split
2025-10-29 14:56:23 [runtime] (split_complete)  ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE
2025-10-29 14:56:23 [runtime] (run:local)       ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE.fork0.join
2025-10-29 15:02:26 [runtime] (update)          ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE.fork0 join_running
2025-10-29 15:08:24 [runtime] (update)          ID.mkref_GRCh38.MAKE_REFERENCE._MAKE_REFERENCE.fork0 join_running
2025-10-29 15:12:58 Caught signal terminated
Terminated
```

## ğŸ“¦ Step 2: Prepare FASTQ Files

Rename and gzip your trimmed FASTQs:

``` bash
gzip data/SRR27960041_1.trimmed.fastq 
gzip data/SRR27960041_2.trimmed.fastq  
mkdir -p fastq/SRR27960041 
mv data/SRR27960041_1.trimmed.fastq.gz fastq/SRR27960041/SRR27960041_S1_L001_R1_001.fastq.gz 
mv data/SRR27960041_2.trimmed.fastq.gz fastq/SRR27960041/SRR27960041_S1_L001_R2_001.fastq.gz 
```

This mimics the 10x directory structure Cell Ranger expects.

## ğŸš€ Step 3: Run Cell Ranger

bash

```         
cellranger count \   
--id=SRR27960041 \
--transcriptome=GRCh38 \   
--fastqs=fastq/SRR27960041 \   
--sample=SRR27960041 \   
--nosecondary \   
--localcores=8 \   
--localmem=32 
```

-   `--id`: output folder name

-   `--transcriptome`: path to reference built in Step 1

-   `--fastqs`: path to FASTQ folder

-   `--sample`: matches FASTQ filename prefix

-   `--nosecondary`: skips web-based analysis

-   `--localcores` and `--localmem`: adjust based on your system

## ğŸ“ Output: `SRR27960041/outs/`

Youâ€™ll get:

-   `filtered_feature_bc_matrix/`: clean count matrix

-   `raw_feature_bc_matrix/`: unfiltered matrix

-   `metrics_summary.csv`: QC stats

-   `web_summary.html`: interactive report

***Still cuz of the computer power,die***

------------------------------------------------------------------------

## ğŸ§­ ç¬¬ 1 æ­¥ï¼šç¡®è®¤å‚è€ƒæ–‡ä»¶å‡†å¤‡æƒ…å†µ {#change}

ä½ å·²ç»æœ‰ï¼š

-   âœ… `gencode.v43.annotation.fixed.gtf`

-   âœ… `gencode.v43.transcripts.fa.gz`ï¼ˆè½¬å½•æœ¬åºåˆ—ï¼‰

-   âœ… `transcripts.idx/`ï¼ˆå·²æ„å»ºå¥½çš„ kallisto ç´¢å¼•ï¼‰

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ kallisto index -i reference/transcripts.idx reference/gencode.v43.transcripts.fa.gz

[build] loading fasta file reference/gencode.v43.transcripts.fa.gz
[build] k-mer length: 31
[build] warning: clipped off poly-A tail (longer than 10)
        from 2020 target sequences
[build] warning: replaced 4 non-ACGUT characters in the input sequence
        with pseudorandom nucleotides
[build] counting k-mers ... done.
[build] building target de Bruijn graph ...  done 
[build] creating equivalence classes ...  done
[build] target de Bruijn graph has 1633342 contigs and contains 150287276 k-mers 
```

è¿˜æ²¡æœ‰ `transcripts_to_genes.txt` æ˜ å°„è¡¨ï¼Œç”¨ä¸‹é¢å‘½ä»¤ç”Ÿæˆï¼š

``` bash
awk '$3 == "transcript" { 
  match($0, /transcript_id "([^"]+)"/, t); 
  match($0, /gene_id "([^"]+)"/, g); 
  if (t[1] && g[1]) print t[1], g[1]; 
}' gencode.v43.annotation.fixed.gtf > transcripts_to_genes.txt
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/reference$ awk '$3 == "transcript" { 
  match($0, /transcript_id "([^"]+)"/, t); 
  match($0, /gene_id "([^"]+)"/, g); 
  if (t[1] && g[1]) print t[1], g[1]; 
}' gencode.v43.annotation.fixed.gtf > transcripts_to_genes.txt

jayz@localhost:/mnt/d/01datawsl/tscrna/reference$ 
jayz@localhost:/mnt/d/01datawsl/tscrna/reference$ ls -lh transcripts_to_genes.txt
-rwxrwxrwx 1 jayz jayz 8.9M Oct 29 16:01 transcripts_to_genes.txt
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ head -n 20 reference/transcripts_to_genes.txt     
ENST00000456328.2 ENSG00000290825.1
ENST00000450305.2 ENSG00000223972.6
ENST00000488147.1 ENSG00000227232.5
ENST00000619216.1 ENSG00000278267.1
ENST00000473358.1 ENSG00000243485.5
ENST00000469289.1 ENSG00000243485.5
ENST00000607096.1 ENSG00000284332.1
ENST00000417324.1 ENSG00000237613.2
ENST00000461467.1 ENSG00000237613.2
ENST00000606857.1 ENSG00000268020.3
ENST00000642116.1 ENSG00000290826.1
ENST00000492842.2 ENSG00000240361.3
ENST00000641515.2 ENSG00000186092.7
ENST00000466430.5 ENSG00000238009.6
ENST00000477740.5 ENSG00000238009.6
ENST00000471248.1 ENSG00000238009.6
ENST00000610542.1 ENSG00000238009.6
ENST00000453576.2 ENSG00000238009.6
ENST00000495576.1 ENSG00000239945.1
ENST00000442987.3 ENSG00000233750.3
```

æˆ‘ä»¬å¯ä»¥ä» GTF æ–‡ä»¶ä¸­æå– `transcript_id` å’Œ `gene_name` å­—æ®µï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„æ˜ å°„è¡¨ã€‚

### ğŸ’» å‘½ä»¤ï¼š

``` bash
awk '$3 == "transcript" {
  match($0, /transcript_id "([^"]+)"/, t);
  match($0, /gene_name "([^"]+)"/, g);
  if (t[1] && g[1]) print t[1], g[1];
}' reference/gencode.v43.annotation.fixed.gtf > reference/transcripts_to_genes_named.txt
```

### ğŸ“‚ è¾“å‡ºæ–‡ä»¶ï¼š

```         
reference/transcripts_to_genes_named.txt 
```

å†…å®¹ç¤ºä¾‹ï¼š

ä»£ç 

```         
ENST00000456328.2 DDX11L1
ENST00000450305.2 WASH7P
ENST00000488147.1 MIR1302-2HG
...
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ head -n 20 reference/transcripts_to_genes_named.txt
ENST00000456328.2 DDX11L2
ENST00000450305.2 DDX11L1
ENST00000488147.1 WASH7P
ENST00000619216.1 MIR6859-1
ENST00000473358.1 MIR1302-2HG
ENST00000469289.1 MIR1302-2HG
ENST00000607096.1 MIR1302-2
ENST00000417324.1 FAM138A
ENST00000461467.1 FAM138A
ENST00000606857.1 OR4G4P
ENST00000642116.1 ENSG00000290826
ENST00000492842.2 OR4G11P
ENST00000641515.2 OR4F5
ENST00000466430.5 ENSG00000238009
ENST00000477740.5 ENSG00000238009
ENST00000471248.1 ENSG00000238009
ENST00000610542.1 ENSG00000238009
ENST00000453576.2 ENSG00000238009
ENST00000495576.1 ENSG00000239945
ENST00000442987.3 CICP27
```

## âœ… ç¬¬ 2 æ­¥ï¼šè¿è¡Œ kallisto bus

### ğŸ“‚ ä½ å½“å‰çš„ç›®å½•ç»“æ„ï¼š

-   FASTQ æ–‡ä»¶ï¼š

    -   `data/SRR27960041_1.trimmed.fastq`

    -   `data/SRR27960041_2.trimmed.fastq`

-   ç´¢å¼•ç›®å½•ï¼š

    -   `reference/transcripts.idx`ï¼ˆå·²æ„å»ºï¼‰

-   è¾“å‡ºç›®å½•ï¼ˆæˆ‘ä»¬å°†åˆ›å»ºï¼‰ï¼š`kallisto_out/`

### ğŸ’» æ‰§è¡Œå‘½ä»¤ï¼š

``` bash
kallisto bus \
  -i reference/transcripts.idx \
  -o kallisto_out \
  -x 10xv3 \
  -t 8 \
  data/SRR27960041_1.trimmed.fastq data/SRR27960041_2.trimmed.fastq
```

è¯´æ˜ï¼š

-   `-i`ï¼šç´¢å¼•æ–‡ä»¶è·¯å¾„

-   `-o`ï¼šè¾“å‡ºç›®å½•

-   `-x 10xv3`ï¼šæŒ‡å®š 10x v3 åŒ–å­¦ç‰ˆæœ¬

-   `-t 8`ï¼šä½¿ç”¨ 8 ä¸ªçº¿ç¨‹ï¼ˆå¯æ ¹æ®ä½ æœºå™¨è°ƒæ•´ï¼‰

### âœ… è¾“å‡ºå†…å®¹ï¼ˆåœ¨ `kallisto_out/` ä¸­ï¼‰ï¼š

-   `output.bus`ï¼šä¸»æ¯”å¯¹ç»“æœ

-   `matrix.ec`ï¼šequivalence classes

-   `transcripts.txt`ï¼šè½¬å½•æœ¬åˆ—è¡¨

-   `run_info.json`ï¼šè¿è¡Œæ—¥å¿—

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna$ kallisto bus \
  -i reference/transcripts.idx \
  -o kallisto_out \
  -x 10xv3 \
  -t 8 \
  data/SRR27960041_1.trimmed.fastq data/SRR27960041_2.trimmed.fastq

[bus] Note: Strand option was not specified; setting it to --fr-stranded for specified technology
[index] k-mer length: 31
[index] number of targets: 252,913
[index] number of k-mers: 150,287,276
[index] number of equivalence classes: 1,090,375
[quant] will process sample 1: data/SRR27960041_1.trimmed.fastq
                               data/SRR27960041_2.trimmed.fastq
[quant] finding pseudoalignments for the reads ... done
[quant] processed 1,882,316 reads, 234,094 reads pseudoaligned
```

-   å…±å¤„ç†äº† **1,882,316 æ¡ reads**

-   æˆåŠŸä¼ªæ¯”å¯¹äº† **234,094 æ¡ reads**

## ğŸ”§ ç¬¬ 3 æ­¥ï¼šä½¿ç”¨ bustools çº é”™å¹¶æ’åº `.bus` æ–‡ä»¶

ç°åœ¨è¿›å…¥ bustools çš„ä¸¤ä¸ªå…³é”®æ­¥éª¤ï¼š

### ğŸ“ä½ç½®ï¼š

bash

```         
/mnt/d/01datawsl/tscrna/kallisto_out 
```

### âœ… 3.1 çº é”™ barcodeï¼ˆä½¿ç”¨ whitelistï¼‰

bash

``` bash
bustools correct \
  -w ../reference/10xv3_whitelist.txt \
  -o output.correct.bus \
  output.bus
```

è¯´æ˜ï¼š

-   `-w`ï¼š10x barcode ç™½åå•

-   `-o`ï¼šè¾“å‡ºçº é”™åçš„ `.bus` æ–‡ä»¶

    ``` bash
    jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ bustools correct \
      -w ../reference/10xv3_whitelist.txt \
      -o output.correct.bus \
      output.bus
    Found 6794880 barcodes in the on-list
    Processed 234094 BUS records
    In on-list = 17184
    Corrected    = 7527
    Uncorrected  = 209383
    ```

### âœ… 3.2 æ’åº `.bus` æ–‡ä»¶ï¼ˆä¸ºåç»­è®¡æ•°åšå‡†å¤‡ï¼‰

bash

```         
bustools sort \
  -t 8 \
  -o output.sorted.bus \
  output.correct.bus
```

è¯´æ˜ï¼š

-   `-t 8`ï¼šä½¿ç”¨ 8 ä¸ªçº¿ç¨‹

-   `-o`ï¼šè¾“å‡ºæ’åºåçš„ `.bus` æ–‡ä»¶

```         
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ bustools sort \
  -t 8 \
  -o output.sorted.bus \
  output.correct.bus
 all fits in buffer
Read in 24711 BUS records
reading time 0.00011s
sorting time 0.001738s
writing time 0.000591s
```

## ğŸ“Š ç¬¬ 5 æ­¥ï¼šç”Ÿæˆè¡¨è¾¾çŸ©é˜µ

æˆ‘ä»¬å°†ä½¿ç”¨ä½ åˆšåˆšç”Ÿæˆçš„ï¼š

-   `output.sorted.bus`

-   `matrix.ec`

-   `transcripts.txt`

-   `reference/transcripts_to_genes_named.txt`ï¼ˆå¸¦åŸºå› åçš„æ˜ å°„è¡¨ï¼‰

bash

``` bash
bustools count \
  -o genes_named \
  -g ../reference/transcripts_to_genes_named.txt \
  -e matrix.ec \
  -t transcripts.txt \
  --genecounts \
  output.sorted.bus
```

è¯´æ˜ï¼š

-   `-g`ï¼šä½¿ç”¨å¸¦åŸºå› åçš„æ˜ å°„è¡¨

-   `--genecounts`ï¼šæŒ‰åŸºå› è®¡æ•°ï¼ˆè€Œä¸æ˜¯è½¬å½•æœ¬ï¼‰

### âœ… è¾“å‡ºæ–‡ä»¶ï¼ˆå‰ç¼€ä¸º `genes_named`ï¼‰ï¼š

-   `genes_named.mtx`ï¼šè¡¨è¾¾çŸ©é˜µï¼ˆç¨€ç–æ ¼å¼ï¼‰

-   `genes_named.genes.txt`ï¼šåŸºå› ååˆ—è¡¨

-   `genes_named.barcodes.txt`ï¼šç»†èƒ barcode åˆ—è¡¨

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ bustools count \
  -o genes_named \
  -g ../reference/transcripts_to_genes_named.txt \
  -e matrix.ec \
  -t transcripts.txt \
  --genecounts \
  output.sorted.bus
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ ls
genes_named.barcodes.txt  matrix.ec           output.sorted.bus
genes_named.genes.txt     output.bus          run_info.json
genes_named.mtx           output.correct.bus  transcripts.txt
```

ç°åœ¨æˆ‘ä»¬æ¥æ£€æŸ¥è¾“å‡ºç»“æœæ˜¯å¦åˆç†ã€‚ä½ åº”è¯¥åœ¨ `kallisto_out/` ç›®å½•ä¸‹çœ‹åˆ°ä»¥ä¸‹ä¸‰ä¸ªæ–‡ä»¶ï¼š

bash

```         
genes_named.mtx genes_named.genes.txt genes_named.barcodes.txt 
```

## âœ… å¿«é€ŸæŸ¥çœ‹å†…å®¹

### 1. æŸ¥çœ‹çŸ©é˜µç»´åº¦ï¼ˆç¨€ç–è¡¨è¾¾çŸ©é˜µï¼‰

``` bash
head -n 20 genes_named.mtx
```

***and it shows 0 and we have to check***

***we get :***

-   `transcripts.txt` ä¸­çš„è½¬å½•æœ¬ ID æ˜¯å®Œæ•´çš„ï¼ˆå¸¦ `.2`, `.1` ç­‰ç‰ˆæœ¬å·ï¼‰

-   `transcripts_to_genes_named.txt` ä¸­çš„è½¬å½•æœ¬ ID ä¹Ÿå¸¦ç‰ˆæœ¬å·

-   æ‰€ä»¥ **ID æ˜¯åŒ¹é…çš„ âœ…**

-   `genes_named.barcodes.txt` æœ‰ 8127 ä¸ªç»†èƒ âœ…

-   ä½† `.mtx` æ˜¯ç©ºçš„ï¼ˆ8127 Ã— 0ï¼‰

è¿™è¯´æ˜é—®é¢˜ä¸åœ¨äº ID æ ¼å¼ä¸åŒ¹é…ï¼Œè€Œå¯èƒ½å‡ºåœ¨ï¼š

## ğŸ” å¯èƒ½åŸå› ï¼š`bustools count` æ²¡æœ‰æ­£ç¡®è¯†åˆ« transcript ID å­—æ®µ

ä½ çš„ `transcripts.txt` æ–‡ä»¶æ ¼å¼æ˜¯ï¼š

ä»£ç 

```         
ENST00000456328.2|ENSG00000290825.1|-|OTTHUMT00000362751.1|DDX11L2-202|DDX11L2|1657|lncRNA| 
```

è€Œ bustools åªä¼šè¯»å– **ç¬¬ä¸€åˆ—ï¼ˆè½¬å½•æœ¬ IDï¼‰**ï¼Œæ‰€ä»¥å®ƒåº”è¯¥æ˜¯èƒ½è¯†åˆ«çš„ã€‚ä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œåªä¿ç•™ç¬¬ä¸€åˆ—ã€‚

## âœ… ä¿®å¤å»ºè®®ï¼šç®€åŒ– `transcripts.txt` æ–‡ä»¶

bash

```         
cut -d '|' -f 1 transcripts.txt > transcripts.clean.txt 
```

ç„¶åé‡æ–°è¿è¡Œ `bustools count`ï¼š

bash

```         
bustools count \
  -o genes_named_clean \
  -g ../reference/transcripts_to_genes_named.txt \
  -e matrix.ec \
  -t transcripts.clean.txt \
  --genecounts \
  output.sorted.bus
```

## ğŸ§ª ä½ å¯ä»¥éªŒè¯æ˜¯å¦ä¿®å¤æˆåŠŸï¼š

```         
head -n 10 genes_named_clean.mtx 
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ head -n 10 genes_named_clean.mtx
%%MatrixMarket matrix coordinate real general
%
8127 61217 11827
1 48031 1
2 60799 1
3 60799 1
4 6796 1
5 60799 1
6 60799 1
7 60799 1
```

è¯´æ˜ï¼š

-   æœ‰ **8127 ä¸ªç»†èƒ**

-   æœ‰ **61217 ä¸ªåŸºå› **

-   æ€»å…± **11827 ä¸ªéé›¶è¡¨è¾¾å€¼**

è¿™è¡¨ç¤ºå·²ç»æˆåŠŸå®Œæˆäº†æ•´ä¸ª **kallisto + bustools** æµç¨‹ï¼Œå¹¶ä¸”å¾—åˆ°äº†ä¸€ä¸ªçœŸå®çš„è¡¨è¾¾çŸ©é˜µï¼

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ head -20 genes_named_clean.genes.txt 
DDX11L2
DDX11L1
WASH7P
MIR6859-1
MIR1302-2HG
MIR1302-2
FAM138A
OR4G4P
ENSG00000290826
OR4G11P
OR4F5
ENSG00000238009
ENSG00000239945
CICP27
ENSG00000268903
ENSG00000269981
ENSG00000239906
ENSG00000241860
RNU6-1100P
ENSG00000241599
```

``` bash
jayz@localhost:/mnt/d/01datawsl/tscrna/kallisto_out$ head -n 20 genes_named_clean.barcodes.txt
AAACCCATCACCATAG
AAACGAAAGTGAACAT
AAAGGATAGACATAAC
AAAGGATGTAGATTAG
AAAGGATGTGTTGAGG
AAAGGTACACACCGAC
AAATGGAGTTTAAGCC
AACAAGAAGCACCGTC
AACCATGAGAACCTTT
AACCATGAGAAGGCTT
AACCATGAGACCTTTG
AACCATGAGAGTCTGG
AACCATGAGATGCGAC
AACCATGAGCAAATCA
AACCATGAGCACCGTC
AACCATGAGCAGTGTA
AACCATGAGCCAGGCA
AACCATGAGCGGCTTT
AACCATGAGCTAAGTG
AACCATGAGGACGAGA
```

```{python}
import scanpy as sc
import matplotlib.pyplot as plt

# Step 1: è¯»å– kallisto + bustools è¾“å‡º
adata = sc.read_10x_mtx(
    r"D:\01datawsl\tscrna\kallisto_out\output",  # æ³¨æ„è·¯å¾„ä¸è¦åŠ é”™
    cache=True
)

# Step 2: æŸ¥çœ‹åŸºæœ¬ä¿¡æ¯
print(adata)
print("ç»†èƒæ•°:", adata.n_obs)
print("åŸºå› æ•°:", adata.n_vars)



```

## âœ… é—®é¢˜æ ¹æº

Matrix Market æ ¼å¼ä¸­ï¼ŒScanpy é»˜è®¤ `.mtx` çš„ç»´åº¦æ˜¯ï¼š

ä»£ç 

```         
rows = genesï¼ˆå˜é‡ï¼‰   columns = cellsï¼ˆè§‚æµ‹ï¼‰ 
```

ä½†ä½ çš„ `.mtx` æ–‡ä»¶å¤´æ˜¯ï¼š

ä»£ç 

```         
8127 61217 11827 
```

è¿™è¡¨ç¤ºï¼š

-   8127 è¡Œï¼ˆScanpy è®¤ä¸ºæ˜¯åŸºå› ï¼‰

-   61217 åˆ—ï¼ˆScanpy è®¤ä¸ºæ˜¯ç»†èƒï¼‰

ä½†ä½ å®é™…çŸ¥é“ï¼š

-   8127 æ˜¯ç»†èƒæ•°ï¼ˆæ¥è‡ª `barcodes.tsv`ï¼‰

-   61217 æ˜¯åŸºå› æ•°ï¼ˆæ¥è‡ª `genes.tsv`ï¼‰

æ‰€ä»¥ Scanpy è¯¯è§£äº† `.mtx` çš„æ–¹å‘ã€‚

## ğŸ›  è§£å†³æ–¹æ³•ï¼šè½¬ç½®è¡¨è¾¾çŸ©é˜µ

ä½ éœ€è¦å°† `.mtx` æ–‡ä»¶è½¬ç½®ï¼Œä½¿å…¶å˜ä¸ºï¼š

ä»£ç 

```         
61217 8127 N 
```

### âœ… æ–¹æ³• 1ï¼šç”¨ `scanpy.read_mtx()` æ‰‹åŠ¨è¯»å–

```{python}
import scanpy as sc
import pandas as pd
from scipy.io import mmread

# Step 1: è¯»å–ç¨€ç–çŸ©é˜µï¼ˆä¸è½¬ç½®ï¼‰
X = mmread("D:/01datawsl/tscrna/kallisto_out/output/matrix.mtx").tocsr()

# Step 2: è¯»å–åŸºå› åå’Œç»†èƒ barcode
genes = pd.read_csv("D:/01datawsl/tscrna/kallisto_out/output/genes.tsv", header=None, sep=None, engine="python")
barcodes = pd.read_csv("D:/01datawsl/tscrna/kallisto_out/output/barcodes.tsv", header=None)

# Step 3: æ„å»º AnnData å¯¹è±¡ï¼ˆæ­£ç¡®èµ‹å€¼ï¼‰
adata = sc.AnnData(X)
adata.obs_names = barcodes[0].values     # âœ… 8127 ä¸ªç»†èƒå
adata.var_names = genes[1].values        # âœ… 61217 ä¸ªåŸºå› å

# Step 4: æ£€æŸ¥
print(adata)

```

è¿™è¡¨ç¤ºï¼š

-   `n_obs = 61217` â†’ æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªç»†èƒï¼ˆä½ ç”¨çš„æ˜¯ `genes[1].values` ä½œä¸º barcodeï¼‰

-   `n_vars = 8127` â†’ æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªåŸºå› ï¼ˆä½ ç”¨çš„æ˜¯ `barcodes[0].values` ä½œä¸º gene symbolï¼‰

è™½ç„¶å˜é‡åæœ‰äº›åç›´è§‰ï¼ˆå› ä¸º bustools çš„ `.mtx` æ˜¯ç»†èƒ Ã— åŸºå› ï¼‰ï¼Œä½†ä½ å·²ç»æ­£ç¡®åœ°è½¬ç½®äº†çŸ©é˜µå¹¶äº¤æ¢äº† `.obs_names` å’Œ `.var_names`ï¼Œç°åœ¨ç»“æ„å®Œå…¨åˆç† âœ…

`AnnData` å¯¹è±¡ï¼š

```         
AnnData object with n_obs Ã— n_vars = 8127 Ã— 61217 
```

è¿™è¡¨ç¤ºï¼š

-   **8127 ä¸ªç»†èƒ**ï¼ˆ`obs_names` æ¥è‡ª `barcodes.tsv`ï¼‰

-   **61217 ä¸ªåŸºå› **ï¼ˆ`var_names` æ¥è‡ª `genes.tsv` ç¬¬äºŒåˆ—

## ğŸ” ç¬¬ä¸€æ­¥ï¼šæŸ¥çœ‹è¡¨è¾¾çŸ©é˜µçš„åŸºæœ¬ä¿¡æ¯

python

```{python}
# æŸ¥çœ‹ç»´åº¦
print(f"ç»†èƒæ•°: {adata.n_obs}, åŸºå› æ•°: {adata.n_vars}")

# æŸ¥çœ‹å‰å‡ è¡Œè¡¨è¾¾çŸ©é˜µï¼ˆç¨€ç–çŸ©é˜µè½¬ä¸º dense å¯èƒ½ä¼šå¾ˆå¤§ï¼Œè¿™é‡Œåªçœ‹å‰å‡ è¡Œå‡ åˆ—ï¼‰
print(adata.X[:5, :5].toarray())

# æŸ¥çœ‹å‰å‡ ä¸ªç»†èƒå’ŒåŸºå› å
print("å‰5ä¸ªç»†èƒ:", adata.obs_names[:5].tolist())
print("å‰5ä¸ªåŸºå› :", adata.var_names[:5].tolist())
```

``` python
ç»†èƒæ•°: 8127, åŸºå› æ•°: 61217
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]]
å‰5ä¸ªç»†èƒ: ['AAACCCATCACCATAG', 'AAACGAAAGTGAACAT', 'AAAGGATAGACATAAC', 'AAAGGATGTAGATTAG', 'AAAGGATGTGTTGAGG']
å‰5ä¸ªåŸºå› : ['DDX11L2', 'DDX11L1', 'WASH7P', 'MIR6859-1', 'MIR1302-2HG']
```

## ğŸ“Š ç¬¬äºŒæ­¥ï¼šç»˜åˆ¶æ¯ä¸ªç»†èƒçš„æ€» UMI æ•°é‡åˆ†å¸ƒï¼ˆå¯è§†åŒ–ï¼‰

python

```{python}
import matplotlib.pyplot as plt
import seaborn as sns

# è®¡ç®—æ¯ä¸ªç»†èƒçš„æ€» counts
adata.obs['n_counts'] = adata.X.sum(axis=1).A1  # .A1 å°†ç¨€ç–çŸ©é˜µè½¬ä¸ºä¸€ç»´æ•°ç»„

# å¯è§†åŒ–ï¼šæ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡åˆ†å¸ƒ
plt.figure(figsize=(6, 4))
sns.histplot(adata.obs['n_counts'], bins=50, kde=False)
plt.xlabel("UMI numbers of all cells")
plt.ylabel("cell number")
plt.title("all cell expression")
plt.tight_layout()
plt.show()
```

![](plot-46.png)

-   æœ‰ **8127 ä¸ªç»†èƒ** å’Œ **61217 ä¸ªåŸºå› **

-   å‰å‡ è¡Œè¡¨è¾¾çŸ©é˜µæ˜¯å…¨ 0ï¼Œè¯´æ˜è¿™äº›ç»†èƒåœ¨è¿™äº›åŸºå› ä¸Šæ²¡æœ‰è¡¨è¾¾ï¼ˆå¾ˆå¸¸è§ï¼‰

-   barcode å’ŒåŸºå› åéƒ½æˆåŠŸè½½å…¥

æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥åšæ ‡å‡†åŒ–å’Œåˆæ­¥å¯è§†åŒ–äº†ã€‚

## ğŸ”¬ ç¬¬ä¸€æ­¥ï¼šæ ‡å‡†åŒ–è¡¨è¾¾çŸ©é˜µ

æˆ‘ä»¬ä½¿ç”¨ Scanpy çš„ `normalize_total` å’Œ `log1p`ï¼š

```{python}
# æ ‡å‡†åŒ–æ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡ä¸º 1e4
sc.pp.normalize_total(adata, target_sum=1e4)

# å¯¹è¡¨è¾¾çŸ©é˜µè¿›è¡Œ log1p è½¬æ¢ï¼ˆå³ log(x + 1)ï¼‰
sc.pp.log1p(adata)
```

è¿™ä¸€æ­¥ä¼šè®©ä¸åŒç»†èƒä¹‹é—´çš„è¡¨è¾¾é‡æ›´å¯æ¯”ï¼Œé€‚åˆåç»­ PCA å’Œ UMAPã€‚

## ğŸ“Š ç¬¬äºŒæ­¥ï¼šå¯è§†åŒ–æ ‡å‡†åŒ–åçš„è¡¨è¾¾é‡åˆ†å¸ƒ

æˆ‘ä»¬å¯ä»¥ç”»å‡ºæ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡åˆ†å¸ƒï¼š

```{python}
import matplotlib.pyplot as plt
import seaborn as sns

# é‡æ–°è®¡ç®—æ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡ï¼ˆæ ‡å‡†åŒ–åï¼‰
adata.obs['n_counts_post_norm'] = adata.X.sum(axis=1).A1

# å¯è§†åŒ–
plt.figure(figsize=(6, 4))
sns.histplot(adata.obs['n_counts_post_norm'], bins=50, kde=False)
plt.xlabel("each cell expression")
plt.ylabel("cell number")
plt.title("expression of all cell (after standardation")
plt.tight_layout()
plt.show()
```

![](plot-47.png)

## ğŸ” ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©é«˜å˜åŸºå› 

python

```{python}
# æ ‡è®°é«˜å˜åŸºå› 
sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)

# æŸ¥çœ‹ç­›é€‰ç»“æœ
print("é«˜å˜åŸºå› æ•°é‡:", adata.var.highly_variable.sum())
```

è¿™ä¸€æ­¥ä¼šåœ¨ `.var` ä¸­æ·»åŠ ä¸€ä¸ªå¸ƒå°”åˆ— `highly_variable`ï¼Œæ ‡è®°å“ªäº›åŸºå› åœ¨ç»†èƒä¹‹é—´å˜å¼‚åº¦é«˜ã€‚

## ğŸ”¬ ç¬¬å››æ­¥ï¼šåªä¿ç•™é«˜å˜åŸºå› ç”¨äºåç»­åˆ†æ

python

```{python}
# å­é›†åŒ–è¡¨è¾¾çŸ©é˜µï¼Œåªä¿ç•™é«˜å˜åŸºå› 
adata = adata[:, adata.var.highly_variable]
print("ç­›é€‰åçŸ©é˜µç»´åº¦:", adata.shape)
```

è¿™ä¸€æ­¥ä¼šæ˜¾è‘—å‡å°‘åŸºå› æ•°é‡ï¼ˆé€šå¸¸ä»å‡ ä¸‡é™åˆ°å‡ åƒï¼‰ï¼Œæé«˜ PCA å’Œèšç±»çš„æ•ˆç‡å’Œè´¨é‡ã€‚

``` python
... print("é«˜å˜åŸºå› æ•°é‡:", adata.var.highly_variable.sum())
é«˜å˜åŸºå› æ•°é‡: 566
>>> # å­é›†åŒ–è¡¨è¾¾çŸ©é˜µï¼Œåªä¿ç•™é«˜å˜åŸºå› 
... adata = adata[:, adata.var.highly_variable]
... print("ç­›é€‰åçŸ©é˜µç»´åº¦:", adata.shape)
ç­›é€‰åçŸ©é˜µç»´åº¦: (8127, 566)
```

## ğŸ”¬ ï¼šPCA é™ç»´

æˆ‘ä»¬å…ˆç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰æ¥å‹ç¼©ç»´åº¦ï¼Œæå–ç»†èƒè¡¨è¾¾çš„ä¸»è¦å˜åŒ–æ–¹å‘ï¼š

python

```{python}
# æ ‡å‡†åŒ–æ¯ä¸ªåŸºå› ï¼ˆå‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ï¼‰
sc.pp.scale(adata, max_value=10)

# PCA é™ç»´
sc.tl.pca(adata, svd_solver='arpack')

# æŸ¥çœ‹å‰å‡ ä¸ªä¸»æˆåˆ†çš„æ–¹å·®è§£é‡Šæ¯”ä¾‹
sc.pl.pca_variance_ratio(adata, log=True)

```

è¿™ä¸€æ­¥ä¼šåœ¨ `adata.obsm['X_pca']` ä¸­ç”Ÿæˆæ¯ä¸ªç»†èƒçš„ PCA åæ ‡ï¼ŒåŒæ—¶åœ¨ `adata.uns['pca']` ä¸­è®°å½•ä¸»æˆåˆ†çš„æ–¹å·®è§£é‡Šæ¯”ä¾‹ã€‚

![](plot-48.png)

## ğŸ§­ ç¬¬ä¸€æ­¥ï¼šPCA ç©ºé—´å¯è§†åŒ–

python

```{python}
# å¯è§†åŒ–å‰ä¸¤ä¸ªä¸»æˆåˆ†
sc.pl.pca(adata, color='n_counts_post_norm', components=['1,2'], title='PCA: PC1 vs PC2')
 
```

![](plot-49.png)

## ğŸŒ ç¬¬äºŒæ­¥ï¼šæ„å»ºé‚»æ¥å›¾ + UMAP é™ç»´

python

```{python}
# æ„å»ºé‚»æ¥å›¾
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=14)

# UMAP é™ç»´
sc.tl.umap(adata)

# å¯è§†åŒ– UMAP
sc.pl.umap(adata, color='n_counts_post_norm', title='UMAP: æ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡')


```

## åˆ—å‡ºè¡¨è¾¾é‡æœ€é«˜çš„åŸºå› ï¼ˆå‡å€¼æ’åºï¼‰

æˆ‘ä»¬å¯ä»¥æŒ‰æ¯ä¸ªåŸºå› åœ¨æ‰€æœ‰ç»†èƒä¸­çš„å¹³å‡è¡¨è¾¾é‡æ’åºï¼š

```{python}
import numpy as np

# è®¡ç®—æ¯ä¸ªåŸºå› çš„å¹³å‡è¡¨è¾¾é‡
gene_means = np.array(adata.X.mean(axis=0)).flatten()

# æ’åºå¹¶åˆ—å‡ºå‰ 10 ä¸ªåŸºå› 
top_mean_idx = np.argsort(gene_means)[::-1][:10]
top_mean_genes = adata.var_names[top_mean_idx]
print("è¡¨è¾¾é‡æœ€é«˜çš„åŸºå› :", top_mean_genes.tolist())
```

``` python
... print("è¡¨è¾¾é‡æœ€é«˜çš„åŸºå› :", top_mean_genes.tolist())
è¡¨è¾¾é‡æœ€é«˜çš„åŸºå› : ['KAZN', 'TXNIP', 'TPTEP1', 'KDELR1', 'ENSG00000286360', 'KIDINS220', 'ACSL3', 'PINLYP', 'ZNF350', 'LBX2-AS1']
```

## ğŸ” äºŒã€åˆ—å‡ºå˜å¼‚åº¦æœ€å¤§çš„åŸºå› ï¼ˆæ ‡å‡†å·®æ’åºï¼‰

```{python}
# è®¡ç®—æ¯ä¸ªåŸºå› çš„æ ‡å‡†å·®
gene_std = np.array(adata.X.std(axis=0)).flatten()

# æ’åºå¹¶åˆ—å‡ºå‰ 10 ä¸ªå˜å¼‚åº¦æœ€å¤§çš„åŸºå› 
top_std_idx = np.argsort(gene_std)[::-1][:10]
top_std_genes = adata.var_names[top_std_idx]
print("å˜å¼‚åº¦æœ€å¤§çš„åŸºå› :", top_std_genes.tolist())
 
```

``` python
å˜å¼‚åº¦æœ€å¤§çš„åŸºå› : ['MT-ND6', 'ACTB', 'AHNAK', 'VIM', 'ENSG00000283907', 'ZFP36', 'FOS', 'EGR1', 'EEF2', 'ENSG00000289606']
```

## ğŸ“Š ä¸‰ã€å¯è§†åŒ–è¿™äº›åŸºå› åœ¨ UMAP ä¸Šçš„è¡¨è¾¾åˆ†å¸ƒ

```{python}
sc.pl.umap(adata, color=top_mean_genes.tolist(), title='UMAP: è¡¨è¾¾é‡æœ€é«˜çš„åŸºå› ')
sc.pl.umap(adata, color=top_std_genes.tolist(), title='UMAP: å˜å¼‚åº¦æœ€å¤§çš„åŸºå› ')
```

![](plot-54.png)

![](plot-53.png)