{
  "hash": "43c7b50650efcc8072a5c6f17cfbdc03",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: ÂåªÁñóÂ§ßÊï∞ÊçÆ‰Ωú‰∏ö\nauthors:\n  - name: Âë®Êù∞ 113120230073\n    affiliation: The GanNan medical University \n    roles: writing\n    corresponding: true\nbibliography: references.bib\n---\n\n what i write is made by myself and AI , i could prove code if you want to check\n\njayz\nÂë®Êù∞ 113120230073\n\n# Getting the dataü§∑\n\nNow we pick the data from TCGA, this is the [link](https://portal.gdc.cancer.gov/projects/TCGA-LUSC)\n\n**Project¬†¬†È°πÁõÆ**\n\n## **TCGA-LUSC**\n\nTotal of¬†¬†ÊÄªËÆ°\n\n**504**Cases¬†¬†Ê°à‰æã\n\n**32,329**Files¬†¬†Êñá‰ª∂\n\n[**3,770**](https://portal.gdc.cancer.gov/projects/TCGA-LUSC#annotations)Annotations¬†¬†Ê≥®Èáä\n\n## **Summary¬†¬†Ê¶ÇÊã¨**\n\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n| **Project ID¬†¬†È°πÁõÆ ID**                   | TCGA-LUSC                                                                                   |\n+===========================================+=============================================================================================+\n| **dbGaP Study Accession¬†¬†dbGaP Á†îÁ©∂Âä†ÂÖ•** | [phs000178](https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000178) |\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n| **Project Name¬†¬†È°πÁõÆÂêçÁß∞**                | Lung Squamous Cell Carcinoma\\                                                               |\n|                                           | ËÇ∫È≥ûÁä∂ÁªÜËÉûÁôå                                                                                |\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n| **Disease Type¬†¬†ÁñæÁóÖÁ±ªÂûã**                | -   2 Disease Types¬†¬†2ÁßçÁñæÁóÖÁ±ªÂûã                                                            |\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n| **Primary Site¬†¬†‰∏ªÁ´ôÁÇπ**                  | Bronchus and lung¬†¬†ÊîØÊ∞îÁÆ°ÂíåËÇ∫                                                               |\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n| **Program¬†¬†Á®ãÂ∫è**                         | TCGA                                                                                        |\n+-------------------------------------------+---------------------------------------------------------------------------------------------+\n\nIn survival analysis, it's often best to combine these stages into **broader prognostic groups** to ensure each group has enough patients and to capture the major jumps in prognosis.\n\n### Clinical Interpretation and Grouping\n\nFor solid tumors like LUSC, a standard way to simplify staging for survival analysis is:\n\n+----------------------+--------------------------+--------------------------------------------------------------+\n| Simplified Group     | Included Original Stages | Clinical Meaning                                             |\n+----------------------+--------------------------+--------------------------------------------------------------+\n| **Early Stage**      | **I (IA, IB)**           | Locally confined tumor, best prognosis.                      |\n+----------------------+--------------------------+--------------------------------------------------------------+\n| **Locally Advanced** | **II (IIA, IIB)**        | Larger tumor or spread to nearby lymph nodes.                |\n+----------------------+--------------------------+--------------------------------------------------------------+\n| **Advanced Stage**   | **III (IIIA, IIIB)**     | Tumor spread to distant lymph nodes or large primary tumors. |\n+----------------------+--------------------------+--------------------------------------------------------------+\n| **Metastatic**       | **IV** (If present)      | Worst prognosis (although LUSC often presents earlier).      |\n+----------------------+--------------------------+--------------------------------------------------------------+\n\nand we have\n\n``` r\n--- Distribution of Simplified Stages ---\n# A tibble: 3 √ó 2\n  simplified_stage             n\n  <chr>                    <int>\n1 Advanced (Stage III)        84\n2 Early/Local (Stage I-II)   405\n3 Unknown                      4\n```\n\n``` r\n--- Survival Model Summary (Log-Rank Test) ---\nCall:\nsurvdiff(formula = surv_object ~ simplified_stage, data = survival_for_analysis)\n\n                                            N Observed Expected (O-E)^2/E (O-E)^2/V\nsimplified_stage=Early/Local (Stage I-II) 405      119    127.2     0.528      2.96\nsimplified_stage=Advanced (Stage III)      84       36     27.8     2.417      2.96\n\n Chisq= 3  on 1 degrees of freedom, p= 0.09 \n \n```\n\n![](plot-9.png)\n\n# Get more meta data from our xml.file\n\nWe're dealing with XML files that use **namespaces**, which are essential for distinguishing elements that might otherwise have the same name but come from different schemas. Here's why and how it works:\n\n### üß† Why we Need to Define Namespaces\n\nXML namespaces are like **last names(ÂßìÊ∞è) for XML tags**‚Äîthey prevent confusion when multiple XML vocabularies are used in the same document.\n\n#### ‚úÖ Purpose of Namespaces\n\n-   Avoids **name collisions** between elements from different sources.\n\n-   Ensures **accurate XPath queries**‚Äîwithout namespaces, `lxml` won‚Äôt find elements like `<shared:bcr_patient_barcode>` because it doesn‚Äôt know what `shared:` means.\n\n-   Allows we to **target specific schemas** (e.g., clinical vs. administrative metadata).\n\n#### üß© Example\n\nwer XML contains:\n\n``` xml\n<shared:bcr_patient_barcode xmlns:shared=\"http://tcga.nci/bcr/xml/shared/2.7\">TCGA-XX-XXXX</shared:bcr_patient_barcode> \n```\n\nTo extract this with XPath, we must tell `lxml` what `shared:` refers to:\n\n``` python\nroot.xpath('//shared:bcr_patient_barcode', namespaces=ns) \n```\n\nWithout `namespaces=ns`, this query fails silently.\n\n### üß¨ Expanded Python XML Parser for TCGA Clinical Metadata\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom lxml import etree\nimport pandas as pd\nimport glob\n\n# Define namespaces\nns = {\n    'shared': 'http://tcga.nci/bcr/xml/shared/2.7',\n    'clin_shared': 'http://tcga.nci/bcr/xml/clinical/shared/2.7',\n    'shared_stage': 'http://tcga.nci/bcr/xml/clinical/shared/stage/2.7',\n    'lung_shared': 'http://tcga.nci/bcr/xml/clinical/shared/lung/2.7',\n    'admin': 'http://tcga.nci/bcr/xml/administration/2.7'\n}\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef parse_clinical_xml(file):\n    tree = etree.parse(file)\n    root = tree.getroot()\n\n    def get_text(xpath):\n        el = root.xpath(xpath, namespaces=ns)\n        return el[0].text if el else None\n\n    return {\n        'case_id': get_text('//shared:bcr_patient_barcode'),\n        'vital_status': get_text('//clin_shared:vital_status'),\n        'days_to_death': get_text('//clin_shared:days_to_death'),\n        'days_to_last_followup': get_text('//clin_shared:days_to_last_followup'),\n        'age_at_dx': get_text('//clin_shared:age_at_initial_pathologic_diagnosis'),\n        'stage': get_text('//shared_stage:pathologic_stage'),\n        'gender': get_text('//shared:gender'),\n        'tumor_status': get_text('//clin_shared:person_neoplasm_cancer_status'),\n        'smoking_history': get_text('//shared:tobacco_smoking_history'),\n        'pack_years_smoked': get_text('//clin_shared:number_pack_years_smoked'),\n        'residual_tumor': get_text('//clin_shared:residual_tumor'),\n        'ecog_score': get_text('//clin_shared:eastern_cancer_oncology_group'),\n        'radiation_therapy': get_text('//clin_shared:radiation_therapy'),\n        'primary_therapy_outcome': get_text('//clin_shared:primary_therapy_outcome_success')\n    }\n\n# Load all XML files\nxml_files = glob.glob(\"E:/acode/wsl/data2/GDCdata/TCGA-LUSC/Clinical/Clinical_Supplement/**/*.xml\", recursive=True)\n\n# Parse and combine\nrecords = [parse_clinical_xml(f) for f in xml_files]\nclinical_df = pd.DataFrame(records)\n\n# Clean numeric columns\nfor col in ['days_to_death', 'days_to_last_followup', 'age_at_dx', 'pack_years_smoked']:\n    clinical_df[col] = pd.to_numeric(clinical_df[col], errors='coerce')\n\n# Preview\nprint(clinical_df.head())\nprint(clinical_df.describe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        case_id vital_status  days_to_death  days_to_last_followup  age_at_dx  \\\n0  TCGA-85-6561        Alive            NaN                   24.0       66.0   \n1  TCGA-37-5819        Alive            NaN                  103.0       64.0   \n2  TCGA-77-8008         Dead         2639.0                    NaN       68.0   \n3  TCGA-56-8083        Alive            NaN                    2.0       56.0   \n4  TCGA-56-A4ZJ        Alive            NaN                   25.0       75.0   \n\n        stage  gender tumor_status smoking_history  pack_years_smoked  \\\n0    Stage IB    MALE   TUMOR FREE               4               35.0   \n1  Stage IIIA    MALE   TUMOR FREE               4               45.0   \n2    Stage IB    MALE         None               4               61.5   \n3    Stage IB    MALE   TUMOR FREE               4               30.0   \n4    Stage IA  FEMALE   TUMOR FREE               4              100.0   \n\n  residual_tumor ecog_score radiation_therapy primary_therapy_outcome  \n0             R0       None              None                    None  \n1             R0          1              None                    None  \n2             R0          1              None                    None  \n3             R0       None              None                    None  \n4             R0       None              None                    None  \n       days_to_death  days_to_last_followup   age_at_dx  pack_years_smoked\ncount     157.000000             383.000000  495.000000         427.000000\nmean      835.598726             585.295039   67.276768          52.913478\nstd       888.682876             796.793252    8.608804          31.156992\nmin         0.000000             -10.000000   39.000000           1.000000\n25%       211.000000              37.000000   62.000000          31.125000\n50%       506.000000             211.000000   68.000000          50.000000\n75%      1114.000000             857.000000   73.000000          64.500000\nmax      5287.000000            4299.000000   90.000000         240.000000\n```\n:::\n:::\n\n\nsave and load the RNA data\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n#  Save clinical metadata\nclinical_outfile = r\"E:\\acode\\wsl\\data2\\GDCdata\\TCGA-LUSC\\clinical_metadata.csv\"\nclinical_df.to_csv(clinical_outfile, index=False)\nprint(f\"‚úÖ Clinical metadata saved to: {clinical_outfile}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ Clinical metadata saved to: E:\\acode\\wsl\\data2\\GDCdata\\TCGA-LUSC\\clinical_metadata.csv\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nclinical_outfile = r\"E:\\acode\\wsl\\data2\\GDCdata\\TCGA-LUSC\\clinical_metadata.csv\"\nclinical_df = pd.read_csv(clinical_outfile)\n# Load RNA expression matrix\nexpression_file = \"E:/acode/wsl/data2/GDCdata/TCGA-LUSC/rnaexp.csv\"\nexpression_df = pd.read_csv(expression_file, index_col=0)\nprint(\"‚úÖ Expression matrix loaded. Shape:\", expression_df.shape)\n\n# Optional: Preview\nprint(expression_df.iloc[:5, :5])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ Expression matrix loaded. Shape: (60664, 563)\n  gene_name  TCGA-90-A4EE  TCGA-85-8049  TCGA-33-6737  TCGA-39-5016\n1    TSPAN6        8.4836        8.9006       24.1585       21.0036\n2      TNMD        0.0149        0.0000        0.0000        0.0587\n3      DPM1       35.1344       25.3093       23.1613       63.1033\n4     SCYL3        3.9120        2.5760        1.2931        3.3603\n5  C1orf112        3.7604        2.8456        2.6190        2.7706\n```\n:::\n:::\n\n\nOur plan for building a system to link clinical and RNA expression data! Using **PostgreSQL** for a robust, production-ready database and **DuckDB** for fast, in-process analytical queries in Python is an excellent approach.\n\nHere is the plan, starting with the necessary packages and steps to load wer data into both systems.\n\n## üì¶ Package Installation\n\nFirst, we'll need to install the required Python packages. we already have **pandas** for data manipulation. we'll need `psycopg2-binary` (or `psycopg` for a modern, pure-Python driver) for PostgreSQL and `duckdb` for the in-process analytics database.\n\n``` bash\n# Recommended installation for the project\npip install pandas duckdb sqlalchemy psycopg2-binary\n```\n\n### Use the postgreSQL database\n\nThis Python script is designed to **load wer TCGA clinical and RNA expression data into a PostgreSQL database** so we can query and manage it efficiently. Here's a breakdown of what each part does:\n\n### üß† What This Code Does\n\n#### 1. **Imports Required Libraries**\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sqlalchemy import create_engine\nimport duckdb\nimport io\n```\n:::\n\n\n-   `pandas`: for handling DataFrames\n\n-   `sqlalchemy`: to connect to PostgreSQL\n\n-   `duckdb` and `io`: not used in this snippet, but could be for in-memory SQL or streaming later\n\n#### 2. **Defines PostgreSQL Connection Parameters**\n\n``` python\nPG_USER = \"wer_user\"\nPG_PASS = \"wer_password\"\nPG_HOST = \"localhost\"\nPG_PORT = \"5432\"\nPG_DB = \"clinical_rna_db\"\n```\n\nThese are placeholders‚Äîwe‚Äôd replace them with wer actual PostgreSQL credentials.\n\n#### 3. **Creates a SQLAlchemy Engine**\n\n``` python\npg_engine_url = f\"postgresql://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\npg_engine = create_engine(pg_engine_url)\n```\n\nThis sets up a connection to wer PostgreSQL database so we can send data to it.\n\n#### 4. **Prepares the Expression Data**\n\n``` python\nexpression_df = expression_df.reset_index(names=['gene_name']) \n```\n\nIf `gene_name` was the index, this makes it a proper column so it can be stored in SQL.\n\n#### 5. **Loads DataFrames into PostgreSQL**\n\n``` python\nclinical_df.to_sql('clinical_metadata', pg_engine, if_exists='replace', index=False) expression_df.to_sql('rna_expression_matrix', pg_engine, if_exists='replace', index=False) \n```\n\n-   `clinical_df` goes into a table called `clinical_metadata`\n\n-   `expression_df` goes into `rna_expression_matrix`\n\n-   `if_exists='replace'` means it will overwrite the table if it already exists\n\n#### 6. **Handles Connection Errors Gracefully**\n\n``` python\nexcept Exception as e:     \n    print(f\"‚ùå Could not connect to PostgreSQL or load data: {e}\") \n```\n\nIf the connection fails (e.g., wrong password, server not running), it prints a helpful error message.\n\n### 2. DuckDB Setup (In-Process, No external server needed)\n\nDuckDB runs entirely within wer Python process, making it perfect for rapid analytical queries.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# --- 2. DuckDB Setup ---\n\n# Create an in-memory database or a file-backed one ('path/to/my.duckdb')\ncon = duckdb.connect(database=':memory:', read_only=False)\nprint(\"‚úÖ DuckDB connection established (in-memory).\")\n\n# --- Loading Data into DuckDB ---\n# DuckDB can read directly from pandas DataFrames using the 'register' function.\n\n# Register the DataFrames as temporary tables in DuckDB\ncon.register('clinical_metadata_db', clinical_df)\ncon.register('rna_expression_matrix_db', expression_df)\n\nprint(\"‚úÖ DataFrames registered as tables in DuckDB.\")\n\n# --- Verification Query in DuckDB ---\n# Example: Querying the registered tables\nduckdb_query = \"\"\"\nSELECT t1.case_id, t1.vital_status, t2.\"TSPAN6\", t2.\"DPM1\"\nFROM clinical_metadata_db t1\nINNER JOIN rna_expression_matrix_db t2\n    ON t1.case_id = t2.case_id  -- Note: we'll need to ensure case_id is a column in expression_df for a direct join!\nLIMIT 5;\n\"\"\"\n# Based on wer data structure, we might need to UNPIVOT the RNA data first in DuckDB\n# The join key is `case_id` from clinical_df and the column *names* (TCGA-...) in expression_df.\n\nprint(\"\\n--- DuckDB Verification Query (Sample) ---\")\ntry:\n    # A crucial step for linking is ensuring the 'case_id' column is present in the expression data.\n    # If the case IDs are the *column names*, we need to *unpivot* the expression matrix first.\n\n    # ‚ùó IMPORTANT: Unpivot the RNA data for easier joining\n    # This assumes the original expression_df has 'gene_name' and columns are 'TCGA-...' case IDs.\n    expression_cols = [col for col in expression_df.columns if col.startswith('TCGA-')]\n\n        # Build struct_pack list\n    structs = ', '.join([\n        f\"struct_pack(case_id := '{col}', expression := \\\"{col}\\\")\"\n        for col in expression_cols\n    ])\n\n    # Corrected SQL: unpack struct fields explicitly\n    unpivot_query = f\"\"\"\n    CREATE TEMP TABLE rna_expression_unpivoted AS\n    SELECT\n        gene_name,\n        s.case_id AS sample_id,\n        s.expression AS expression\n    FROM (\n        SELECT\n            gene_name,\n            unnest(list_value(\n                {', '.join([\n                    f\"struct_pack(case_id := '{col}', expression := \\\"{col}\\\")\"\n                    for col in expression_cols\n                ])}\n            )) AS s\n        FROM rna_expression_matrix_db\n    );\n    \"\"\"\n    con.execute(unpivot_query)\n    print(\"‚úÖ RNA expression matrix unpivoted and flattened.\")\n\n    print(\"‚úÖ RNA expression matrix unpivoted and cleaned for linking.\")\n\n\n    # Now, the join is straightforward\n    linking_query = \"\"\"\n    SELECT\n        t1.case_id,\n        t1.vital_status,\n        t1.age_at_dx,\n        t2.gene_name,\n        t2.sample_id,\n        t2.expression\n    FROM clinical_metadata_db t1\n    INNER JOIN rna_expression_unpivoted t2\n        ON t1.case_id = t2.sample_id\n        LIMIT 10;\n    \n    \"\"\"\n    linked_data = con.execute(linking_query).fetchdf()\n    print(\"Successfully linked clinical and expression data (sample):\")\n    print(linked_data)\n\nexcept Exception as e:\n    print(f\"‚ùå DuckDB query/unpivot failed: {e}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ DuckDB connection established (in-memory).\n‚úÖ DataFrames registered as tables in DuckDB.\n\n--- DuckDB Verification Query (Sample) ---\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\nFloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ RNA expression matrix unpivoted and flattened.\n‚úÖ RNA expression matrix unpivoted and cleaned for linking.\nSuccessfully linked clinical and expression data (sample):\n        case_id vital_status  age_at_dx gene_name     sample_id  expression\n0  TCGA-90-A4EE        Alive       53.0    TSPAN6  TCGA-90-A4EE      8.4836\n1  TCGA-85-8049        Alive       57.0    TSPAN6  TCGA-85-8049      8.9006\n2  TCGA-33-6737         None        NaN    TSPAN6  TCGA-33-6737     24.1585\n3  TCGA-39-5016        Alive       44.0    TSPAN6  TCGA-39-5016     21.0036\n4  TCGA-56-8304        Alive       73.0    TSPAN6  TCGA-56-8304     14.7462\n5  TCGA-92-8063        Alive       52.0    TSPAN6  TCGA-92-8063     11.5989\n6  TCGA-22-4593         Dead       77.0    TSPAN6  TCGA-22-4593     21.0880\n7  TCGA-43-8115        Alive       72.0    TSPAN6  TCGA-43-8115     10.2988\n8  TCGA-22-4599         Dead       73.0    TSPAN6  TCGA-22-4599     12.1437\n9  TCGA-60-2712         Dead       79.0    TSPAN6  TCGA-60-2712      5.9034\n```\n:::\n:::\n\n\nThis script is a **complete local pipeline** that uses **DuckDB** to join wer TCGA clinical metadata and RNA expression matrix‚Äîwithout needing PostgreSQL or any external database. Here's a breakdown of what it's doing and why it's clever:\n\n``` python\n        case_id vital_status  age_at_dx gene_name     sample_id  expression\n0  TCGA-90-A4EE        Alive       53.0    TSPAN6  TCGA-90-A4EE      8.4836\n1  TCGA-85-8049        Alive       57.0    TSPAN6  TCGA-85-8049      8.9006\n2  TCGA-33-6737         None        NaN    TSPAN6  TCGA-33-6737     24.1585\n3  TCGA-39-5016        Alive       44.0    TSPAN6  TCGA-39-5016     21.0036\n4  TCGA-56-8304        Alive       73.0    TSPAN6  TCGA-56-8304     14.7462\n5  TCGA-92-8063        Alive       52.0    TSPAN6  TCGA-92-8063     11.5989\n6  TCGA-22-4593         Dead       77.0    TSPAN6  TCGA-22-4593     21.0880\n7  TCGA-43-8115        Alive       72.0    TSPAN6  TCGA-43-8115     10.2988\n8  TCGA-22-4599         Dead       73.0    TSPAN6  TCGA-22-4599     12.1437\n9  TCGA-60-2712         Dead       79.0    TSPAN6  TCGA-60-2712      5.9034\nTotal unique clinical samples: 504\n```\n\n### üß† What This DuckDB Script Does\n\n#### ‚úÖ 1. **Creates an In-Memory DuckDB Database**\n\n``` python\ncon = duckdb.connect(database=':memory:', read_only=False)\n```\n\n-   Fast, lightweight, and no installation overhead.\n\n-   we could also use a file-backed DB by replacing `':memory:'` with a path like `'E:/acode/my_tcga.duckdb'`.\n\n#### ‚úÖ 2. **Registers Pandas DataFrames as DuckDB Tables**\n\n``` python\ncon.register('clinical_metadata_db', clinical_df) con.register('rna_expression_matrix_db', expression_df) \n```\n\n-   These are **temporary views**‚Äîwe can query them like SQL tables.\n\n-   No need to write to disk or convert formats.\n\n#### ‚ö†Ô∏è 3. **Unpivots the RNA Expression Matrix**\n\n``` python\nexpression_cols = [f'\"{col}\"' for col in expression_df.columns if col.startswith('TCGA-')] \n```\n\n-   wer expression matrix is **wide format**: genes as rows, samples as columns.\n\n-   To join with clinical data (which is long format), we **unpivot** it:\n\n    -   Each row becomes: `(gene_name, case_id, expression)`\n\n    -   This is done using DuckDB‚Äôs `unnest(list_value(...))` + `struct_pack(...)`\n\n#### üîó 4. **Joins Clinical and Expression Data**\n\n``` sql\nSELECT\n    t1.case_id,\n    t1.vital_status,\n    t1.age_at_dx,\n    t2.gene_name,\n    t2.expression\nFROM clinical_metadata_db t1\nINNER JOIN rna_expression_unpivoted t2\n    ON t1.case_id = t2.case_id\nWHERE t2.gene_name IN ('TSPAN6', 'DPM1')\n```\n\n-   Now that both tables have a `case_id` column, we can join them directly.\n\n-   This query filters for two genes (`TSPAN6`, `DPM1`) and returns their expression values alongside clinical metadata.\n\n### ‚úÖ Why This Is Smart\n\n-   **No PostgreSQL setup** needed‚Äîperfect for local analysis.\n\n-   **DuckDB is blazing fast** for analytical queries on tabular data.\n\n-   we can now run complex SQL joins, filters, and aggregations entirely in memory.\n\n## üîó The Liking/Linking Strategy\n\nThe core challenge in wer data is that the two DataFrames have different structures for the common key:\n\n-   **`clinical_df`**: Has a column named `case_id` (e.g., `TCGA-85-6561`).\n\n-   **`expression_df`**: Has `gene_name` as an ID, but the patient IDs (`TCGA-90-A4EE`, etc.) are the **column names**.\n\nTo perform a relational join (a \"liking\" in wer terms), the `expression_df` must be *unpivoted* (or *melted*) so that all patient IDs are in a single column.\n\nThe Python code above uses a **DuckDB SQL `UNPIVOT`/`UNNEST`** technique to transform the wide RNA matrix into a long format (`case_id`, `gene_name`, `expression`), which is the **correct relational structure for joining** with the `clinical_metadata` table. This is the key step to \"build the liking\" between wer datasets.\n\n## 1. DuckDB SQL: How the Samples Were Linked\n\nThe connection between the `clinical_metadata_db` and the `rna_expression_matrix_db` is built in two key SQL steps, which are necessary because the patient IDs (e.g., `TCGA-90-A4EE`) exist as **column names** in the expression data but as **row values** (`case_id`) in the clinical data.\n\n### Step 1: Unpivoting the RNA Expression Data (The Key \"Liking\" Step)\n\nThe first step creates a temporary table in the correct relational format.\n\n```         \nCREATE TEMP TABLE rna_expression_unpivoted AS\nSELECT\n    gene_name,\n    unnest(list_value(\n        -- This part manually creates a structured list of {case_id, expression} pairs\n        struct_pack(case_id := 'TCGA-90-A4EE', expression := \"TCGA-90-A4EE\"),\n        struct_pack(case_id := 'TCGA-85-8049', expression := \"TCGA-85-8049\"),\n        -- ... and so on for all patient columns\n        ...\n    )).*\nFROM rna_expression_matrix_db;\n```\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nlinking_query1 = \"\"\"\nSELECT\n    t1.case_id,\n    t1.vital_status,\n    t1.age_at_dx,\n    t2.gene_name,\n    t2.sample_id,\n    t2.expression\nFROM clinical_metadata_db t1\nINNER JOIN rna_expression_unpivoted t2\n    ON t1.case_id = t2.sample_id\nWHERE t2.gene_name IN ('TSPAN6', 'DPM1')\nLIMIT 1000;\n\"\"\"\ncursor = con.execute(linking_query1).fetchdf()\n```\n:::\n\n\nBased on the padj‚Äã values we provided, a common threshold for significance is padj‚Äã\\<0.05.\n\n### 1. Identify Truly Significant Genes\n\nWe will filter the genes we provided to select those that meet the statistical significance threshold of padj‚Äã\\<0.05.\n\n|              |        |                           |\n|--------------|--------|---------------------------|\n| Gene         | padj‚Äã   | Significant (padj‚Äã\\<0.05)? |\n| **HSD17B14** | 0.0176 | **YES**                   |\n| **CLTA**     | 0.0176 | **YES**                   |\n| **C9orf72**  | 0.0206 | **YES**                   |\n| **TTC39A**   | 0.0268 | **YES**                   |\n| **C4orf48**  | 0.0306 | **YES**                   |\n| **TESK1**    | 0.0366 | **YES**                   |\n| **FAM241B**  | 0.0413 | **YES**                   |\n| C5           | 0.0536 | NO                        |\n| TP53I3       | 0.0536 | NO                        |\n| SLC39A4      | 0.0536 | NO                        |\n| CLDN3        | 0.0536 | NO                        |\n| NRIP3        | 0.0536 | NO                        |\n| PYCR1        | 0.0561 | NO                        |\n| MT1M         | 0.0777 | NO                        |\n| H19          | 0.0821 | NO                        |\n| PSD3         | 0.0821 | NO                        |\n| ETNK1        | 0.0942 | NO                        |\n| HMGB3        | 0.0966 | NO                        |\n| TRPM2        | 0.0966 | NO                        |\n| MELK         | 0.0966 | NO                        |\n| HILPDA       | 0.0969 | NO                        |\n| ATP23        | 0.0969 | NO                        |\n| IFFO2        | 0.0969 | NO                        |\n| TMEM80       | 0.0969 | NO                        |\n| PRAG1        | 0.0969 | NO                        |\n| SVIP         | 0.0984 | NO                        |\n\n**The 7 Significant Genes (**padj‚Äã\\<0.05) are: `HSD17B14`, `CLTA`, `C9orf72`, `TTC39A`, `C4orf48`, `TESK1`, and `FAM241B`.\n\n### 2. DuckDB Query for Survival Analysis Data\n\nWe will use the **unpivoted expression table** (`rna_expression_unpivoted`) and the **clinical metadata table** (`clinical_metadata_db`) to extract the exact data needed for survival analysis.\n\nTo perform survival analysis using DuckDB, we‚Äôll need to:\n\n1.  **Filter the expression data** for wer 7 significant genes.\n\n2.  **Join** it with clinical metadata (especially `vital_status`, `days_to_death`, `days_to_last_followup`).\n\n3.  **Create a survival-ready table** with one row per patient, including expression values and survival time/status.\n\n4.  **Export** that table to Python (e.g., for use with `lifelines` or `scikit-survival`).\n\n### Step-by-Step DuckDB Query for Survival Prep\n\nHere‚Äôs how to build the query:\n\n#### ‚úÖ 1. Define wer Gene List in SQL\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nsignificant_genes = ['HSD17B14', 'CLTA', 'C9orf72', 'TTC39A', 'C4orf48', 'TESK1', 'FAM241B']\ngene_list_sql = ', '.join([f\"'{gene}'\" for gene in significant_genes])\n```\n:::\n\n\n#### ‚úÖ 2. Query to Build Survival Table\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nsurvival_query = f\"\"\"\nSELECT\n    t1.case_id,\n    t1.vital_status,\n    COALESCE(t1.days_to_death, t1.days_to_last_followup) AS survival_days,\n    t1.age_at_dx,\n    t2.gene_name,\n    t2.expression\nFROM clinical_metadata_db t1\nINNER JOIN rna_expression_unpivoted t2\n    ON t1.case_id = t2.sample_id\nWHERE t2.gene_name IN ({gene_list_sql})\n\"\"\"\n```\n:::\n\n\n#### ‚úÖ 3. Fetch and Pivot in Python\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsurvival_df_long = con.execute(survival_query).fetchdf()\n\n# Pivot to wide format: one row per patient\nsurvival_df = survival_df_long.pivot_table(\n    index=['case_id', 'vital_status', 'survival_days', 'age_at_dx'],\n    columns='gene_name',\n    values='expression'\n).reset_index()\n\nprint(\"‚úÖ Survival-ready DataFrame:\")\nprint(survival_df.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ Survival-ready DataFrame:\ngene_name       case_id vital_status  survival_days  age_at_dx  C4orf48  \\\n0          TCGA-18-3406         Dead          371.0       67.0   2.8345   \n1          TCGA-18-3407         Dead          136.0       72.0   1.3487   \n2          TCGA-18-3408        Alive         2099.0       77.0   0.0538   \n3          TCGA-18-3409        Alive         2417.0       74.0   1.2988   \n4          TCGA-18-3410         Dead          146.0       81.0   6.3692   \n\ngene_name  C9orf72      CLTA  FAM241B  HSD17B14    TESK1  TTC39A  \n0           3.4351  149.4185   7.8203    6.8117  11.0774  1.7314  \n1           7.9812   51.1565   3.7595    3.3361  13.5017  0.7852  \n2          15.6769   80.5977  13.0744    2.2227   7.7895  1.2734  \n3           1.5068   39.9578  14.0642    9.4156   8.2695  0.3505  \n4           0.9963   43.2127  13.9918    3.8372  10.0191  2.1708  \n```\n:::\n:::\n\n\nsave\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nsurvival_df.to_csv(r\"E:\\acode\\wsl\\data2\\GDCdata\\TCGA-LUSC\\survial_data.csv\")\n```\n:::\n\n\n``` python\n‚úÖ Survival-ready DataFrame:\ngene_name       case_id vital_status  survival_days  age_at_dx  ...  FAM241B  HSD17B14    TESK1  TTC39A\n0          TCGA-18-3406         Dead          371.0       67.0  ...   7.8203    6.8117  11.0774  1.7314\n1          TCGA-18-3407         Dead          136.0       72.0  ...   3.7595    3.3361  13.5017  0.7852\n2          TCGA-18-3408        Alive         2099.0       77.0  ...  13.0744    2.2227   7.7895  1.2734\n3          TCGA-18-3409        Alive         2417.0       74.0  ...  14.0642    9.4156   8.2695  0.3505\n4          TCGA-18-3410         Dead          146.0       81.0  ...  13.9918    3.8372  10.0191  2.1708\n\n[5 rows x 11 columns]\n```\n\n## survival analysis\n\n### ‚úÖ Step 1: Convert `vital_status` to Binary\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Convert 'Dead' ‚Üí 1, 'Alive' ‚Üí 0\nsurvival_df['event'] = survival_df['vital_status'].map({'Dead': 1, 'Alive': 0})\n```\n:::\n\n\n### ‚úÖ Step 2: Check Column Types\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nprint(survival_df.dtypes) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\ngene_name\ncase_id           object\nvital_status      object\nsurvival_days    float64\nage_at_dx        float64\nC4orf48          float64\nC9orf72          float64\nCLTA             float64\nFAM241B          float64\nHSD17B14         float64\nTESK1            float64\nTTC39A           float64\nevent              int64\ndtype: object\n```\n:::\n:::\n\n\nwe want:\n\n-   `survival_days`: float or int\n\n-   `event`: int (0/1)\n\n-   Gene columns: float\n\n-   `age_at_dx`: float or int\n\nIf anything is `object`, convert it:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nsurvival_df['survival_days'] = pd.to_numeric(survival_df['survival_days'], errors='coerce')\nsurvival_df['age_at_dx'] = pd.to_numeric(survival_df['age_at_dx'], errors='coerce')\n```\n:::\n\n\n### ‚úÖ Step 3: KNN impute the miss data\n\n#### ‚úÖ Apply KNN Imputer\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.impute import KNNImputer\n\n# Select columns to impute (excluding case_id and vital_status)\nimpute_cols = ['survival_days', 'age_at_dx'] + significant_genes\n\n# Create a copy to avoid modifying original\nimpute_df = survival_df[impute_cols].copy()\n\n# Initialize the imputer\nimputer = KNNImputer(n_neighbors=10)\n\n# Fit and transform\nimputed_array = imputer.fit_transform(impute_df)\n\n# Replace the original columns with imputed values\nsurvival_df[impute_cols] = imputed_array\n```\n:::\n\n\n### ‚úÖ Step 4: Run Kaplan-Meier Survival Curves\n\nHere‚Äôs an example for one gene (`TESK1`):\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom lifelines import KaplanMeierFitter\nimport matplotlib.pyplot as plt\n\n# Median split\nsurvival_df['TESK1_group'] = survival_df['TESK1'] > survival_df['TESK1'].median()\n\nkmf = KaplanMeierFitter()\n\nplt.figure(figsize=(8, 6))\nfor group in [True, False]:\n    mask = survival_df['TESK1_group'] == group\n    label = 'High TESK1' if group else 'Low TESK1'\n    kmf.fit(survival_df.loc[mask, 'survival_days'], survival_df.loc[mask, 'event'], label=label)\n    kmf.plot_survival_function()\n\nplt.title(\"Kaplan-Meier Survival Curve: TESK1\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Survival Probability\")\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](sql_files/figure-docx/cell-17-output-1.png){}\n:::\n:::\n\n\n### ‚úÖ Step 5: Fit Cox Proportional Hazards Model\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom lifelines import CoxPHFitter\n\ncox_df = survival_df[['survival_days', 'event', 'age_at_dx'] + significant_genes]\ncph = CoxPHFitter()\ncph.fit(cox_df, duration_col='survival_days', event_col='event')\ncph.print_summary()\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n\\begin{tabular}{lrrrrrrrrrrr}\n & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\ncovariate &  &  &  &  &  &  &  &  &  &  &  \\\\\nage_at_dx & 0.02 & 1.02 & 0.01 & 0.00 & 0.05 & 1.00 & 1.05 & 0.00 & 2.19 & 0.03 & 5.12 \\\\\nHSD17B14 & -0.01 & 0.99 & 0.01 & -0.02 & 0.01 & 0.98 & 1.01 & 0.00 & -0.73 & 0.46 & 1.11 \\\\\nCLTA & -0.00 & 1.00 & 0.00 & -0.01 & 0.00 & 0.99 & 1.00 & 0.00 & -0.60 & 0.55 & 0.87 \\\\\nC9orf72 & -0.00 & 1.00 & 0.03 & -0.06 & 0.05 & 0.95 & 1.05 & 0.00 & -0.09 & 0.93 & 0.10 \\\\\nTTC39A & 0.09 & 1.09 & 0.04 & 0.00 & 0.18 & 1.00 & 1.19 & 0.00 & 1.99 & 0.05 & 4.41 \\\\\nC4orf48 & 0.02 & 1.02 & 0.01 & -0.00 & 0.04 & 1.00 & 1.04 & 0.00 & 1.51 & 0.13 & 2.93 \\\\\nTESK1 & 0.00 & 1.00 & 0.01 & -0.01 & 0.02 & 0.99 & 1.02 & 0.00 & 0.48 & 0.63 & 0.66 \\\\\nFAM241B & -0.01 & 0.99 & 0.01 & -0.03 & 0.02 & 0.97 & 1.02 & 0.00 & -0.35 & 0.73 & 0.46 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n| model                     | lifelines.CoxPHFitter   |\n|---------------------------|-------------------------|\n| duration col              | 'survival_days'         |\n| event col                 | 'event'                 |\n| baseline estimation       | breslow                 |\n| number of observations    | 489                     |\n| number of events observed | 154                     |\n| partial log-likelihood    | -757.38                 |\n| time fit was run          | 2025-10-13 13:42:02 UTC |\n\n|   | coef | exp(coef) | se(coef) | coef lower 95% | coef upper 95% | exp(coef) lower 95% | exp(coef) upper 95% | cmp to | z | p | -log2(p) |\n|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|\n| age_at_dx | 0.02 | 1.02 | 0.01 | 0.00 | 0.05 | 1.00 | 1.05 | 0.00 | 2.19 | 0.03 | 5.12 |\n| HSD17B14 | -0.01 | 0.99 | 0.01 | -0.02 | 0.01 | 0.98 | 1.01 | 0.00 | -0.73 | 0.46 | 1.11 |\n| CLTA | -0.00 | 1.00 | 0.00 | -0.01 | 0.00 | 0.99 | 1.00 | 0.00 | -0.60 | 0.55 | 0.87 |\n| C9orf72 | -0.00 | 1.00 | 0.03 | -0.06 | 0.05 | 0.95 | 1.05 | 0.00 | -0.09 | 0.93 | 0.10 |\n| TTC39A | 0.09 | 1.09 | 0.04 | 0.00 | 0.18 | 1.00 | 1.19 | 0.00 | 1.99 | 0.05 | 4.41 |\n| C4orf48 | 0.02 | 1.02 | 0.01 | -0.00 | 0.04 | 1.00 | 1.04 | 0.00 | 1.51 | 0.13 | 2.93 |\n| TESK1 | 0.00 | 1.00 | 0.01 | -0.01 | 0.02 | 0.99 | 1.02 | 0.00 | 0.48 | 0.63 | 0.66 |\n| FAM241B | -0.01 | 0.99 | 0.01 | -0.03 | 0.02 | 0.97 | 1.02 | 0.00 | -0.35 | 0.73 | 0.46 |\n\n![](data2/plot-28.png)\n\n1.  **Run a Cox model with all 7 genes together**\n\n2.  **Stratify by clinical features like stage or gender**\n\n3.  **Visualize hazard ratios with confidence intervals**\n\n### üß¨ 1. use the TTC39A\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfrom lifelines import KaplanMeierFitter\nimport matplotlib.pyplot as plt\n\n# Median split\nsurvival_df['TTC39A_group'] = survival_df['TTC39A'] > survival_df['TTC39A'].median()\n\nkmf = KaplanMeierFitter()\n\nplt.figure(figsize=(8, 6))\nfor group in [True, False]:\n    mask = survival_df['TTC39A_group'] == group\n    label = 'High TTC39A' if group else 'Low TTC39A'\n    kmf.fit(survival_df.loc[mask, 'survival_days'], survival_df.loc[mask, 'event'], label=label)\n    kmf.plot_survival_function()\n\nplt.title(\"Kaplan-Meier Survival Curve: TTC39A\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Survival Probability\")\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](sql_files/figure-docx/cell-19-output-1.png){}\n:::\n:::\n\n\n![](plot-29.png)\n\n### üß† 2. Stratify by Clinical Features (e.g. Stage, Gender)\n\n**Stratification** means analyzing survival within subgroups to see if gene effects differ.\n\n#### Example: Stratify by `gender`\n\nI have not extracted the meta data like tis ,so skip\n\nwe can do the same for `stage`, `tumor_status`, or any other clinical variable.\n\n### üìä 3. Visualize Hazard Ratios with Confidence Intervals\n\nUse `lifelines` to generate a forest plot:\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n# Plot hazard ratios\nax = cph.plot(hazard_ratios=True)\n\n# Customize the plot afterward\nfig = ax.get_figure()\nfig.set_size_inches(8, 6)\nplt.title(\"Hazard Ratios for 7 Significant Genes\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](sql_files/figure-docx/cell-20-output-1.png){}\n:::\n:::\n\n\nThis plot shows:\n\n-   HR \\> 1: higher risk\n\n-   HR \\< 1: protective effect\n\n-   Confidence intervals: statistical certainty\n\n![](data2/plot-29.png)\n\n## Seems our so called significant genes is not significant at all\n\nThe most important genes in **Lung Squamous Cell Carcinoma (LUSC)**, particularly those frequently altered or associated with prognosis (survival), include:\n\n## Key Driver and Highly Mutated Genes\n\nThese genes are frequently mutated or altered in LUSC and are considered major drivers of the disease:\n\n-   TP53: This is the most commonly mutated gene in LUSC, with a mutation frequency of **over 80%**. As a tumor suppressor gene, its inactivation is a critical event in LUSC development.\n\n-   CDKN2A: This tumor suppressor gene is often lost or deleted. It's an important factor in cell cycle regulation.\n\n-   PIK3CA: Mutations in this gene activate the PI3K signaling pathway, which promotes cell growth and survival, making it an important driver.\n\n-   NFE2L2: Alterations in this gene are also a frequent driver in LUSC, involved in antioxidant response.\n\n-   SOX2 and TP63: These genes are often overexpressed and amplified, acting as spectrum factors that help define the squamous cell type.\n\n### ‚úÖ Updated Gene List (LUSC Drivers)\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nsignificant_genes = ['TP53', 'CDKN2A', 'PIK3CA', 'NFE2L2', 'SOX2', 'TP63']\ngene_list_sql = ', '.join([f\"'{gene}'\" for gene in significant_genes])\n\n```\n:::\n\n\n### ‚úÖ Updated DuckDB Query\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nsurvival_query = f\"\"\"\nSELECT\n    t1.case_id,\n    t1.vital_status,\n    COALESCE(t1.days_to_death, t1.days_to_last_followup) AS survival_days,\n    t1.age_at_dx,\n    t2.gene_name,\n    t2.expression\nFROM clinical_metadata_db t1\nINNER JOIN rna_expression_unpivoted t2\n    ON t1.case_id = t2.sample_id\nWHERE t2.gene_name IN ({gene_list_sql})\n\"\"\"\nsurvival_df_long = con.execute(survival_query).fetchdf()\n```\n:::\n\n\n### ‚úÖ Pivot to Wide Format\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nsurvival_df = survival_df_long.pivot_table(\n    index=['case_id', 'vital_status', 'survival_days', 'age_at_dx'],\n    columns='gene_name',\n    values='expression'\n).reset_index()\n\nprint(\"‚úÖ Survival-ready DataFrame:\")\nprint(survival_df.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ Survival-ready DataFrame:\ngene_name       case_id vital_status  survival_days  age_at_dx   CDKN2A  \\\n0          TCGA-18-3406         Dead          371.0       67.0   0.1111   \n1          TCGA-18-3407         Dead          136.0       72.0   7.8677   \n2          TCGA-18-3408        Alive         2099.0       77.0  14.7748   \n3          TCGA-18-3409        Alive         2417.0       74.0   4.5390   \n4          TCGA-18-3410         Dead          146.0       81.0   0.1752   \n\ngene_name    NFE2L2   PIK3CA      SOX2     TP53      TP63  \n0           71.1991   3.5253    7.8118  11.1669   91.2031  \n1          102.7201   3.5564  101.7467   4.4468  197.8747  \n2          116.5379  17.2093  229.6729  25.1026  137.9216  \n3           28.1534   2.8343    0.7877   6.0767   97.3364  \n4           28.7284   2.0180   13.9919  46.3015   19.8604  \n```\n:::\n:::\n\n\n### üíæ Save to CSV\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nsurvival_df.to_csv(r\"E:\\acode\\wsl\\data2\\GDCdata\\TCGA-LUSC\\survial_data.csv\", index=False)\n```\n:::\n\n\n## üß† Step 1: Impute Missing Values (KNN)\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# Select columns to impute (excluding case_id and vital_status)\nimpute_cols = ['survival_days', 'age_at_dx'] + significant_genes\n\n# Create a copy to avoid modifying original\nimpute_df = survival_df[impute_cols].copy()\n\n# Initialize the imputer\nimputer = KNNImputer(n_neighbors=10)\n\n# Fit and transform\nimputed_array = imputer.fit_transform(impute_df)\n\n# Replace the original columns with imputed values\nsurvival_df[impute_cols] = imputed_array\n```\n:::\n\n\n## üîÅ Step 2: Convert `vital_status` to Binary Event\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nsurvival_df['event'] = survival_df['vital_status'].map({'Dead': 1, 'Alive': 0}).astype(int)\n```\n:::\n\n\n### ‚öñÔ∏è Step 2: Z-score Normalization (Standardization)\n\nThis centers each gene‚Äôs expression around 0 and scales by standard deviation:\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nsurvival_df[significant_genes] = scaler.fit_transform(survival_df[significant_genes])\n```\n:::\n\n\n## üìä Step 3: Run Multivariate Cox\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nfrom lifelines import CoxPHFitter\n\ncox_df = survival_df[['survival_days', 'event', 'age_at_dx'] + significant_genes]\ncph = CoxPHFitter()\ncph.fit(cox_df, duration_col='survival_days', event_col='event')\ncph.print_summary()\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n\\begin{tabular}{lrrrrrrrrrrr}\n & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\ncovariate &  &  &  &  &  &  &  &  &  &  &  \\\\\nage_at_dx & 0.02 & 1.02 & 0.01 & 0.00 & 0.04 & 1.00 & 1.04 & 0.00 & 2.15 & 0.03 & 4.99 \\\\\nTP53 & -0.03 & 0.97 & 0.08 & -0.19 & 0.12 & 0.83 & 1.13 & 0.00 & -0.42 & 0.68 & 0.56 \\\\\nCDKN2A & -0.11 & 0.90 & 0.09 & -0.29 & 0.07 & 0.75 & 1.07 & 0.00 & -1.21 & 0.23 & 2.15 \\\\\nPIK3CA & -0.08 & 0.92 & 0.10 & -0.28 & 0.11 & 0.75 & 1.12 & 0.00 & -0.83 & 0.40 & 1.31 \\\\\nNFE2L2 & 0.08 & 1.08 & 0.10 & -0.12 & 0.28 & 0.88 & 1.32 & 0.00 & 0.75 & 0.45 & 1.14 \\\\\nSOX2 & -0.08 & 0.92 & 0.12 & -0.33 & 0.16 & 0.72 & 1.17 & 0.00 & -0.69 & 0.49 & 1.03 \\\\\nTP63 & -0.15 & 0.86 & 0.12 & -0.37 & 0.08 & 0.69 & 1.08 & 0.00 & -1.26 & 0.21 & 2.27 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n| model                     | lifelines.CoxPHFitter   |\n|---------------------------|-------------------------|\n| duration col              | 'survival_days'         |\n| event col                 | 'event'                 |\n| baseline estimation       | breslow                 |\n| number of observations    | 489                     |\n| number of events observed | 154                     |\n| partial log-likelihood    | -755.72                 |\n| time fit was run          | 2025-10-13 14:17:05 UTC |\n\n|   | coef | exp(coef) | se(coef) | coef lower 95% | coef upper 95% | exp(coef) lower 95% | exp(coef) upper 95% | cmp to | z | p | -log2(p) |\n|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|\n| age_at_dx | 0.02 | 1.02 | 0.01 | 0.00 | 0.04 | 1.00 | 1.04 | 0.00 | 2.15 | 0.03 | 4.99 |\n| TP53 | -0.00 | 1.00 | 0.01 | -0.02 | 0.01 | 0.98 | 1.01 | 0.00 | -0.42 | 0.68 | 0.56 |\n| CDKN2A | -0.01 | 0.99 | 0.01 | -0.02 | 0.01 | 0.98 | 1.01 | 0.00 | -1.21 | 0.23 | 2.15 |\n| PIK3CA | -0.04 | 0.96 | 0.04 | -0.12 | 0.05 | 0.89 | 1.05 | 0.00 | -0.83 | 0.40 | 1.31 |\n| NFE2L2 | 0.00 | 1.00 | 0.00 | -0.00 | 0.01 | 1.00 | 1.01 | 0.00 | 0.75 | 0.45 | 1.14 |\n| SOX2 | -0.00 | 1.00 | 0.00 | -0.00 | 0.00 | 1.00 | 1.00 | 0.00 | -0.69 | 0.49 | 1.03 |\n| TP63 | -0.00 | 1.00 | 0.00 | -0.01 | 0.00 | 0.99 | 1.00 | 0.00 | -1.26 | 0.21 | 2.27 |\n\n| Concordance               | 0.59          |\n|---------------------------|---------------|\n| Partial AIC               | 1525.45       |\n| log-likelihood ratio test | 13.45 on 7 df |\n| -log2(p) of ll-ratio test | 4.01          |\n\n## üìà Step 4: Visualize Hazard Ratios\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nax = cph.plot(hazard_ratios=True)\nfig = ax.get_figure()\nfig.set_size_inches(8, 6)\nplt.title(\"Hazard Ratios for LUSC Driver Genes\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](sql_files/figure-docx/cell-29-output-1.png){}\n:::\n:::\n\n\n![](data2/plot-291.png)\n\n## üß™ Step 5: Explore Gene-Gene Interactions or Build Risk Score\n\n### Option A: Interaction Terms\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\ncox_df['TP53_x_PIK3CA'] = cox_df['TP53'] * cox_df['PIK3CA']\ncph.fit(cox_df, duration_col='survival_days', event_col='event')\ncph.print_summary()\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n\\begin{tabular}{lrrrrrrrrrrr}\n & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\ncovariate &  &  &  &  &  &  &  &  &  &  &  \\\\\nage_at_dx & 0.02 & 1.02 & 0.01 & 0.00 & 0.04 & 1.00 & 1.04 & 0.00 & 2.08 & 0.04 & 4.73 \\\\\nTP53 & -0.03 & 0.97 & 0.08 & -0.19 & 0.14 & 0.83 & 1.14 & 0.00 & -0.32 & 0.75 & 0.41 \\\\\nCDKN2A & -0.09 & 0.91 & 0.09 & -0.27 & 0.09 & 0.76 & 1.09 & 0.00 & -1.01 & 0.31 & 1.68 \\\\\nPIK3CA & -0.14 & 0.87 & 0.11 & -0.35 & 0.08 & 0.70 & 1.08 & 0.00 & -1.24 & 0.22 & 2.22 \\\\\nNFE2L2 & 0.06 & 1.07 & 0.10 & -0.14 & 0.27 & 0.87 & 1.30 & 0.00 & 0.63 & 0.53 & 0.93 \\\\\nSOX2 & -0.09 & 0.92 & 0.12 & -0.33 & 0.15 & 0.72 & 1.17 & 0.00 & -0.70 & 0.48 & 1.05 \\\\\nTP63 & -0.13 & 0.88 & 0.11 & -0.35 & 0.09 & 0.70 & 1.10 & 0.00 & -1.15 & 0.25 & 2.01 \\\\\nTP53_x_PIK3CA & 0.14 & 1.15 & 0.08 & -0.03 & 0.30 & 0.97 & 1.35 & 0.00 & 1.61 & 0.11 & 3.23 \\\\\n\\end{tabular}\n\n:::\n:::\n\n\n### Option B: Risk Score (linear combination of weighted expression)\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nrisk_score = cph.predict_partial_hazard(cox_df)\nsurvival_df['risk_score'] = risk_score.values\nprint(survival_df['risk_score'].head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0    1.153991\n1    0.968188\n2    0.894628\n3    1.335779\n4    1.279238\nName: risk_score, dtype: float64\n```\n:::\n:::\n\n\n```         \n... print(survival_df['risk_score'].head())\n0    1.153991\n1    0.968188\n2    0.894628\n3    1.335779\n4    1.279238\n```\n\nhold on ,i think it is not good at all,the data sucks i guess ,fuck it\n\n",
    "supporting": [
      "sql_files"
    ],
    "filters": []
  }
}